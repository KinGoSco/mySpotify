{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea47581e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Setup rapide avec 5.0% des données\n",
      "INFO:__main__:Chargement des triplets...\n",
      "INFO:__main__:Triplets chargés: 2,418,679 interactions\n",
      "INFO:__main__:Chargement du mapping tracks...\n",
      "INFO:__main__:Tracks chargés: 1,000,000\n",
      "INFO:__main__:Setup terminé!\n",
      "INFO:__main__:Utilisateurs: 753,334\n",
      "INFO:__main__:Chansons: 205,653\n",
      "INFO:__main__:Sparsité: 100.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP-10 TRACKS:\n",
      "   index                                             artist  \\\n",
      "0      1                                      Dwight Yoakam   \n",
      "1      2                                              Björk   \n",
      "2      3                                      Kings Of Leon   \n",
      "3      4                                           Harmonia   \n",
      "4      5  Barry Tuckwell/Academy of St Martin-in-the-Fie...   \n",
      "5      6                             Florence + The Machine   \n",
      "6      7                                        OneRepublic   \n",
      "7      8                                   Five Iron Frenzy   \n",
      "8      9                                           Tub Ring   \n",
      "9     10                                    Alliance Ethnik   \n",
      "\n",
      "                                               title  play_count  \n",
      "0                                     You're The One       36584  \n",
      "1                                               Undo       32141  \n",
      "2                                            Revelry       27803  \n",
      "3                                      Sehr kosmisch       20676  \n",
      "4  Horn Concerto No. 4 in E flat K495: II. Romanc...       18925  \n",
      "5                     Dog Days Are Over (Radio Edit)       17572  \n",
      "6                                            Secrets       15197  \n",
      "7                                             Canada       13314  \n",
      "8                                            Invalid       13198  \n",
      "9                                         Représente       11913  \n",
      "\n",
      "RECOMMANDATIONS POUR 470c65144c49b122c4be2ea008cba342b7af2a9d:\n",
      "   index            artist           title     score\n",
      "0      1  Hollywood Undead       The Diary  1.011524\n",
      "1      2  Hollywood Undead  Immigrant Song  0.050576\n"
     ]
    }
   ],
   "source": [
    "# Templates de Code MySpotify - Prêts à l'emploi\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import logging\n",
    "\n",
    "# Configuration logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Chargeur de données optimisé pour MSD\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "    \n",
    "    def load_triplets(self, sample_frac=None):\n",
    "        \"\"\"Charge les triplets avec option d'échantillonnage\"\"\"\n",
    "        logger.info(\"Chargement des triplets...\")\n",
    "        \n",
    "        # Chargement par chunks pour gros fichiers\n",
    "        chunks = []\n",
    "        chunksize = 100000\n",
    "        \n",
    "        for chunk in pd.read_csv(\n",
    "            f\"{self.data_path}/train_triplets.txt\", \n",
    "            sep='\\t', \n",
    "            names=['user_id', 'song_id', 'play_count'],\n",
    "            chunksize=chunksize\n",
    "        ):\n",
    "            if sample_frac:\n",
    "                chunk = chunk.sample(frac=sample_frac)\n",
    "            chunks.append(chunk)\n",
    "        \n",
    "        df = pd.concat(chunks, ignore_index=True)\n",
    "        logger.info(f\"Triplets chargés: {len(df):,} interactions\")\n",
    "        return df\n",
    "    \n",
    "    def load_tracks(self):\n",
    "        \"\"\"Charge le mapping tracks\"\"\"\n",
    "        logger.info(\"Chargement du mapping tracks...\")\n",
    "        \n",
    "        df = pd.read_csv(\n",
    "            f\"{self.data_path}/p02_unique_tracks.txt\",\n",
    "            sep='<SEP>',\n",
    "            names=['track_id', 'song_id', 'artist', 'title'],\n",
    "            engine='python'\n",
    "        )\n",
    "        logger.info(f\"Tracks chargés: {len(df):,}\")\n",
    "        return df\n",
    "    \n",
    "    def load_lyrics(self):\n",
    "        \"\"\"Charge les données de paroles musiXmatch\"\"\"\n",
    "        logger.info(\"Chargement des paroles...\")\n",
    "        \n",
    "        lyrics_data = []\n",
    "        word_mapping = {}\n",
    "        \n",
    "        with open(f\"{self.data_path}/mxm_dataset_train.txt\", 'r') as f:\n",
    "            for line_num, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Skip comments\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                \n",
    "                # Parse word mapping\n",
    "                if line.startswith('%'):\n",
    "                    words = line[1:].split(',')\n",
    "                    word_mapping = {i+1: word for i, word in enumerate(words)}\n",
    "                    continue\n",
    "                \n",
    "                # Parse song data\n",
    "                parts = line.split(',')\n",
    "                if len(parts) < 2:\n",
    "                    continue\n",
    "                \n",
    "                track_id = parts[0]\n",
    "                mxm_track_id = parts[1]\n",
    "                \n",
    "                # Parse word counts (sparse format)\n",
    "                word_counts = {}\n",
    "                for part in parts[2:]:\n",
    "                    if ':' in part:\n",
    "                        try:\n",
    "                            word_idx, count = part.split(':')\n",
    "                            word_counts[int(word_idx)] = int(count)\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "                \n",
    "                lyrics_data.append({\n",
    "                    'track_id': track_id,\n",
    "                    'mxm_track_id': mxm_track_id,\n",
    "                    'word_counts': word_counts\n",
    "                })\n",
    "        \n",
    "        df = pd.DataFrame(lyrics_data)\n",
    "        logger.info(f\"Paroles chargées: {len(df):,} tracks\")\n",
    "        return df, word_mapping\n",
    "    \n",
    "    def load_genres(self):\n",
    "        \"\"\"Charge les annotations de genres\"\"\"\n",
    "        logger.info(\"Chargement des genres...\")\n",
    "        \n",
    "        df = pd.read_csv(\n",
    "            f\"{self.data_path}/p02_msd_tagtraum_cd2.cls\",\n",
    "            sep='\\t',\n",
    "            names=['track_id', 'majority_genre', 'minority_genre'],\n",
    "            comment='#'\n",
    "        )\n",
    "        logger.info(f\"Genres chargés: {len(df):,}\")\n",
    "        return df\n",
    "\n",
    "class QuickStartRecommender:\n",
    "    \"\"\"Version simplifiée pour démarrage rapide\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        self.data_loader = DataLoader(data_path)\n",
    "        self.triplets_df = None\n",
    "        self.tracks_df = None\n",
    "        self.user_to_idx = {}\n",
    "        self.song_to_idx = {}\n",
    "        self.user_item_matrix = None\n",
    "        \n",
    "    def quick_setup(self, sample_frac=0.1):\n",
    "        \"\"\"Setup rapide avec échantillon de données\"\"\"\n",
    "        logger.info(f\"Setup rapide avec {sample_frac*100}% des données\")\n",
    "        \n",
    "        # Chargement\n",
    "        self.triplets_df = self.data_loader.load_triplets(sample_frac)\n",
    "        self.tracks_df = self.data_loader.load_tracks()\n",
    "        \n",
    "        # Filtrage pour cohérence\n",
    "        valid_songs = set(self.tracks_df['song_id'])\n",
    "        self.triplets_df = self.triplets_df[\n",
    "            self.triplets_df['song_id'].isin(valid_songs)\n",
    "        ]\n",
    "        \n",
    "        # Mappings\n",
    "        unique_users = self.triplets_df['user_id'].unique()\n",
    "        unique_songs = self.triplets_df['song_id'].unique()\n",
    "        \n",
    "        self.user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.song_to_idx = {song: idx for idx, song in enumerate(unique_songs)}\n",
    "        \n",
    "        # Matrice user-item\n",
    "        user_indices = self.triplets_df['user_id'].map(self.user_to_idx)\n",
    "        song_indices = self.triplets_df['song_id'].map(self.song_to_idx)\n",
    "        play_counts = self.triplets_df['play_count']\n",
    "        \n",
    "        self.user_item_matrix = csr_matrix(\n",
    "            (play_counts, (user_indices, song_indices)),\n",
    "            shape=(len(self.user_to_idx), len(self.song_to_idx))\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Setup terminé!\")\n",
    "        logger.info(f\"Utilisateurs: {len(self.user_to_idx):,}\")\n",
    "        logger.info(f\"Chansons: {len(self.song_to_idx):,}\")\n",
    "        logger.info(f\"Sparsité: {(1 - self.user_item_matrix.nnz / np.prod(self.user_item_matrix.shape))*100:.2f}%\")\n",
    "    \n",
    "    def get_top_tracks(self, n=250):\n",
    "        \"\"\"TOP-250 TRACKS - Version simple\"\"\"\n",
    "        popularity = self.triplets_df.groupby('song_id')['play_count'].sum()\n",
    "        top_songs = popularity.nlargest(n)\n",
    "        \n",
    "        results = []\n",
    "        for i, (song_id, play_count) in enumerate(top_songs.items(), 1):\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            if not track_info.empty:\n",
    "                track_info = track_info.iloc[0]\n",
    "                results.append({\n",
    "                    'index': i,\n",
    "                    'artist': track_info['artist'],\n",
    "                    'title': track_info['title'],\n",
    "                    'play_count': int(play_count)\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def simple_user_recommendations(self, user_id, n=10):\n",
    "        \"\"\"Recommandations utilisateur simplifiées\"\"\"\n",
    "        if user_id not in self.user_to_idx:\n",
    "            logger.warning(f\"Utilisateur {user_id} non trouvé\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        user_idx = self.user_to_idx[user_id]\n",
    "        user_vector = self.user_item_matrix[user_idx]\n",
    "        \n",
    "        # Calcul simple de similarité avec quelques utilisateurs\n",
    "        sample_size = min(1000, self.user_item_matrix.shape[0])\n",
    "        sample_indices = np.random.choice(\n",
    "            self.user_item_matrix.shape[0], \n",
    "            sample_size, \n",
    "            replace=False\n",
    "        )\n",
    "        sample_matrix = self.user_item_matrix[sample_indices]\n",
    "        \n",
    "        similarities = cosine_similarity(user_vector, sample_matrix).flatten()\n",
    "        \n",
    "        # Agréger les recommandations\n",
    "        recommendations = np.zeros(self.user_item_matrix.shape[1])\n",
    "        user_items = user_vector.toarray().flatten()\n",
    "        \n",
    "        for i, sim_idx in enumerate(sample_indices):\n",
    "            if sim_idx == user_idx:\n",
    "                continue\n",
    "            \n",
    "            similarity = similarities[i]\n",
    "            similar_user_items = self.user_item_matrix[sim_idx].toarray().flatten()\n",
    "            \n",
    "            # Items non écoutés par l'utilisateur cible\n",
    "            unseen_mask = (user_items == 0) & (similar_user_items > 0)\n",
    "            recommendations[unseen_mask] += similarity * similar_user_items[unseen_mask]\n",
    "        \n",
    "        # Top recommandations\n",
    "        top_indices = np.argsort(recommendations)[::-1][:n]\n",
    "        \n",
    "        # Formatage des résultats\n",
    "        results = []\n",
    "        idx_to_song = {v: k for k, v in self.song_to_idx.items()}\n",
    "        \n",
    "        for i, song_idx in enumerate(top_indices, 1):\n",
    "            if recommendations[song_idx] > 0:\n",
    "                song_id = idx_to_song[song_idx]\n",
    "                track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "                if not track_info.empty:\n",
    "                    track_info = track_info.iloc[0]\n",
    "                    results.append({\n",
    "                        'index': i,\n",
    "                        'artist': track_info['artist'],\n",
    "                        'title': track_info['title'],\n",
    "                        'score': recommendations[song_idx]\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def evaluate_precision_at_k(true_items, recommended_items, k=10):\n",
    "    \"\"\"Calcule Precision@k simple\"\"\"\n",
    "    if len(true_items) == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    recommended_k = set(recommended_items[:k])\n",
    "    true_set = set(true_items)\n",
    "    \n",
    "    hits = len(recommended_k.intersection(true_set))\n",
    "    return hits / k\n",
    "\n",
    "# EXEMPLE D'UTILISATION\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup rapide\n",
    "    recommender = QuickStartRecommender(\"../data\")\n",
    "    recommender.quick_setup(sample_frac=0.05)  # 5% des données pour test\n",
    "    \n",
    "    # Test Top-250\n",
    "    top_tracks = recommender.get_top_tracks(10)\n",
    "    print(\"TOP-10 TRACKS:\")\n",
    "    print(top_tracks)\n",
    "    print()\n",
    "    \n",
    "    # Test recommandations utilisateur\n",
    "    sample_user = list(recommender.user_to_idx.keys())[0]\n",
    "    user_recs = recommender.simple_user_recommendations(sample_user, n=5)\n",
    "    print(f\"RECOMMANDATIONS POUR {sample_user}:\")\n",
    "    print(user_recs)\n",
    "\n",
    "# TEMPLATE POUR COLLECTIONS THÉMATIQUES\n",
    "class ThematicCollectionTemplate:\n",
    "    \"\"\"Template pour collections thématiques\"\"\"\n",
    "    \n",
    "    def __init__(self, lyrics_df, word_mapping, tracks_df, triplets_df):\n",
    "        self.lyrics_df = lyrics_df\n",
    "        self.word_mapping = word_mapping\n",
    "        self.tracks_df = tracks_df\n",
    "        self.triplets_df = triplets_df\n",
    "        \n",
    "        # Index inversé mot -> index\n",
    "        self.word_to_idx = {word: idx for idx, word in word_mapping.items()}\n",
    "    \n",
    "    def get_love_songs(self, n=50):\n",
    "        \"\"\"Collection de chansons d'amour - méthode baseline\"\"\"\n",
    "        love_keywords = ['love', 'heart', 'kiss', 'babi', 'darlin', 'honey']\n",
    "        \n",
    "        song_scores = defaultdict(int)\n",
    "        \n",
    "        for _, row in self.lyrics_df.iterrows():\n",
    "            track_id = row['track_id']\n",
    "            word_counts = row['word_counts']\n",
    "            \n",
    "            # Score basé sur les mots-clés d'amour\n",
    "            love_score = 0\n",
    "            for keyword in love_keywords:\n",
    "                if keyword in self.word_to_idx:\n",
    "                    word_idx = self.word_to_idx[keyword]\n",
    "                    if word_idx in word_counts:\n",
    "                        love_score += word_counts[word_idx]\n",
    "            \n",
    "            if love_score > 0:\n",
    "                song_scores[track_id] = love_score\n",
    "        \n",
    "        # Tri par score puis popularité\n",
    "        sorted_tracks = sorted(\n",
    "            song_scores.items(), \n",
    "            key=lambda x: x[1], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        # Formatage avec info tracks\n",
    "        results = []\n",
    "        for i, (track_id, score) in enumerate(sorted_tracks[:n], 1):\n",
    "            # Mapping track_id -> song_id\n",
    "            track_match = self.tracks_df[self.tracks_df['track_id'] == track_id]\n",
    "            if not track_match.empty:\n",
    "                song_id = track_match.iloc[0]['song_id']\n",
    "                \n",
    "                # Popularité\n",
    "                popularity = self.triplets_df[\n",
    "                    self.triplets_df['song_id'] == song_id\n",
    "                ]['play_count'].sum()\n",
    "                \n",
    "                results.append({\n",
    "                    'index': i,\n",
    "                    'artist': track_match.iloc[0]['artist'],\n",
    "                    'title': track_match.iloc[0]['title'],\n",
    "                    'love_score': score,\n",
    "                    'play_count': popularity\n",
    "                })\n",
    "        \n",
    "        # Tri final par play_count\n",
    "        results.sort(key=lambda x: x['play_count'], reverse=True)\n",
    "        return pd.DataFrame(results[:n])\n",
    "\n",
    "# TEMPLATE TRAIN/TEST SPLIT\n",
    "class SimpleEvaluator:\n",
    "    \"\"\"Evaluateur simple pour démarrer\"\"\"\n",
    "    \n",
    "    def __init__(self, user_item_matrix, user_to_idx, song_to_idx):\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.user_to_idx = user_to_idx\n",
    "        self.song_to_idx = song_to_idx\n",
    "    \n",
    "    def simple_train_test_split(self, test_ratio=0.2):\n",
    "        \"\"\"Split simple - masque aléatoirement des interactions\"\"\"\n",
    "        train_matrix = self.user_item_matrix.copy()\n",
    "        test_interactions = {}\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        \n",
    "        for user_idx in range(self.user_item_matrix.shape[0]):\n",
    "            user_songs = self.user_item_matrix[user_idx].nonzero()[1]\n",
    "            \n",
    "            if len(user_songs) > 2:  # Au moins 3 chansons\n",
    "                n_test = max(1, int(len(user_songs) * test_ratio))\n",
    "                test_songs = np.random.choice(user_songs, n_test, replace=False)\n",
    "                \n",
    "                # Masquer dans train\n",
    "                for song_idx in test_songs:\n",
    "                    train_matrix[user_idx, song_idx] = 0\n",
    "                \n",
    "                # Sauvegarder pour test\n",
    "                test_interactions[user_idx] = test_songs\n",
    "        \n",
    "        train_matrix.eliminate_zeros()\n",
    "        return train_matrix, test_interactions\n",
    "    \n",
    "    def evaluate_recommendations(self, recommendations_dict, test_interactions, k=10):\n",
    "        \"\"\"Évalue les recommandations avec P@k\"\"\"\n",
    "        precisions = []\n",
    "        idx_to_song = {v: k for k, v in self.song_to_idx.items()}\n",
    "        \n",
    "        for user_id, recs in recommendations_dict.items():\n",
    "            if user_id not in self.user_to_idx:\n",
    "                continue\n",
    "                \n",
    "            user_idx = self.user_to_idx[user_id]\n",
    "            if user_idx not in test_interactions:\n",
    "                continue\n",
    "            \n",
    "            # Items de test pour cet utilisateur\n",
    "            true_items = test_interactions[user_idx]\n",
    "            \n",
    "            # Items recommandés (convertir song_id en indices)\n",
    "            rec_items = []\n",
    "            for rec in recs[:k]:\n",
    "                if 'song_id' in rec and rec['song_id'] in self.song_to_idx:\n",
    "                    rec_items.append(self.song_to_idx[rec['song_id']])\n",
    "            \n",
    "            # Calculer P@k\n",
    "            hits = len(set(rec_items).intersection(set(true_items)))\n",
    "            precision = hits / k\n",
    "            precisions.append(precision)\n",
    "        \n",
    "        return np.mean(precisions) if precisions else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff2f8f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratégie de chargement par chunks pour gros fichiers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def load_triplets_chunked(filepath, chunksize=100000):\n",
    "    \"\"\"Charge les triplets par chunks pour éviter les problèmes mémoire\"\"\"\n",
    "    chunks = []\n",
    "    for chunk in pd.read_csv(filepath, sep='\\t', chunksize=chunksize, \n",
    "                             names=['user_id', 'song_id', 'play_count']):\n",
    "        chunks.append(chunk)\n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "398ea9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.user_to_idx = {}\n",
    "        self.song_to_idx = {}\n",
    "        self.idx_to_user = {}\n",
    "        self.idx_to_song = {}\n",
    "    \n",
    "    def create_mappings(self, triplets_df):\n",
    "        \"\"\"Crée les mappings bidirectionnels user/song ↔ index\"\"\"\n",
    "        unique_users = triplets_df['user_id'].unique()\n",
    "        unique_songs = triplets_df['song_id'].unique()\n",
    "        \n",
    "        self.user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.song_to_idx = {song: idx for idx, song in enumerate(unique_songs)}\n",
    "        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}\n",
    "        self.idx_to_song = {idx: song for song, idx in self.song_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c79d734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_item_matrix(self, triplets_df):\n",
    "    \"\"\"Construit la matrice user-item sparse\"\"\"\n",
    "    user_indices = triplets_df['user_id'].map(self.user_to_idx)\n",
    "    song_indices = triplets_df['song_id'].map(self.song_to_idx)\n",
    "    play_counts = triplets_df['play_count']\n",
    "    \n",
    "    matrix = csr_matrix((play_counts, (user_indices, song_indices)),\n",
    "                       shape=(len(self.user_to_idx), len(self.song_to_idx)))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a44cb450",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PopularityRecommender:\n",
    "    def __init__(self, tracks_df, triplets_df):\n",
    "        self.tracks_df = tracks_df\n",
    "        self.triplets_df = triplets_df\n",
    "    \n",
    "    def get_top_tracks(self, n=250):\n",
    "        \"\"\"Retourne les n tracks les plus populaires\"\"\"\n",
    "        popularity = self.triplets_df.groupby('song_id')['play_count'].sum()\n",
    "        top_songs = popularity.nlargest(n).index\n",
    "        \n",
    "        result = []\n",
    "        for i, song_id in enumerate(top_songs, 1):\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id].iloc[0]\n",
    "            result.append({\n",
    "                'index': i,\n",
    "                'artist': track_info['artist'],\n",
    "                'title': track_info['title'],\n",
    "                'play_count': popularity[song_id]\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac840fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenreRecommender:\n",
    "    def __init__(self, tracks_df, triplets_df, genre_df):\n",
    "        self.tracks_df = tracks_df\n",
    "        self.triplets_df = triplets_df\n",
    "        self.genre_df = genre_df\n",
    "    \n",
    "    def get_top_by_genre(self, genre, n=100):\n",
    "        \"\"\"Retourne les n tracks les plus populaires pour un genre\"\"\"\n",
    "        # Filtrer par genre\n",
    "        genre_tracks = self.genre_df[self.genre_df['majority_genre'] == genre]['track_id']\n",
    "        \n",
    "        # Mapper track_id vers song_id\n",
    "        genre_songs = self.tracks_df[self.tracks_df['track_id'].isin(genre_tracks)]['song_id']\n",
    "        \n",
    "        # Calculer popularité dans ce genre\n",
    "        genre_triplets = self.triplets_df[self.triplets_df['song_id'].isin(genre_songs)]\n",
    "        popularity = genre_triplets.groupby('song_id')['play_count'].sum()\n",
    "        \n",
    "        return self._format_results(popularity.nlargest(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e353835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThematicCollections:\n",
    "    def __init__(self, lyrics_df, tracks_df, triplets_df):\n",
    "        self.lyrics_df = lyrics_df\n",
    "        self.tracks_df = tracks_df\n",
    "        self.triplets_df = triplets_df\n",
    "        self.word_mapping = self._load_word_mapping()\n",
    "    \n",
    "    def _load_word_mapping(self):\n",
    "        \"\"\"Charge le mapping des mots du dataset musiXmatch\"\"\"\n",
    "        # Première ligne contient les top words séparés par virgules\n",
    "        with open('mxm_dataset_train.txt', 'r') as f:\n",
    "            for line in f:\n",
    "                if line.startswith('%'):\n",
    "                    words = line[1:].strip().split(',')\n",
    "                    return {i+1: word for i, word in enumerate(words)}\n",
    "    \n",
    "    def get_thematic_collection(self, theme, n=50, method='baseline'):\n",
    "        \"\"\"Retourne une collection thématique\"\"\"\n",
    "        if method == 'baseline':\n",
    "            return self._baseline_method(theme, n)\n",
    "        elif method == 'word2vec':\n",
    "            return self._word2vec_method(theme, n)\n",
    "        elif method == 'classification':\n",
    "            return self._classification_method(theme, n)\n",
    "    \n",
    "    def _baseline_method(self, theme, n):\n",
    "        \"\"\"Méthode baseline : recherche directe du mot-clé\"\"\"\n",
    "        theme_word_idx = None\n",
    "        for idx, word in self.word_mapping.items():\n",
    "            if theme.lower() in word.lower():\n",
    "                theme_word_idx = idx\n",
    "                break\n",
    "        \n",
    "        if not theme_word_idx:\n",
    "            return pd.DataFrame()  # Mot non trouvé\n",
    "        \n",
    "        # Filtrer les chansons contenant ce mot\n",
    "        theme_songs = []\n",
    "        for _, row in self.lyrics_df.iterrows():\n",
    "            word_counts = self._parse_sparse_format(row)\n",
    "            if theme_word_idx in word_counts:\n",
    "                theme_songs.append((row['track_id'], word_counts[theme_word_idx]))\n",
    "        \n",
    "        # Trier par fréquence du mot-thème puis par popularité\n",
    "        return self._rank_and_format(theme_songs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5ddf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserBasedCF:\n",
    "    def __init__(self, user_item_matrix, preprocessor):\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.preprocessor = preprocessor\n",
    "        self.user_similarity_matrix = None\n",
    "    \n",
    "    def compute_user_similarity(self, metric='cosine'):\n",
    "        \"\"\"Calcule la matrice de similarité entre utilisateurs\"\"\"\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        \n",
    "        # Normalisation pour cosine similarity\n",
    "        normalized_matrix = self.user_item_matrix.copy()\n",
    "        normalized_matrix.data = normalized_matrix.data / np.sqrt(\n",
    "            np.array(normalized_matrix.sum(axis=1)).flatten()\n",
    "        )\n",
    "        \n",
    "        self.user_similarity_matrix = cosine_similarity(normalized_matrix)\n",
    "        return self.user_similarity_matrix\n",
    "    \n",
    "    def recommend_for_user(self, user_id, n_recommendations=10, n_neighbors=50):\n",
    "        \"\"\"Génère des recommandations pour un utilisateur\"\"\"\n",
    "        if user_id not in self.preprocessor.user_to_idx:\n",
    "            return pd.DataFrame()  # Utilisateur non trouvé\n",
    "        \n",
    "        user_idx = self.preprocessor.user_to_idx[user_id]\n",
    "        \n",
    "        # Trouver les utilisateurs similaires\n",
    "        user_similarities = self.user_similarity_matrix[user_idx]\n",
    "        similar_users = np.argsort(user_similarities)[::-1][1:n_neighbors+1]\n",
    "        \n",
    "        # Calculer les scores de recommandation\n",
    "        user_items = self.user_item_matrix[user_idx].toarray()[0]\n",
    "        recommendations = np.zeros(self.user_item_matrix.shape[1])\n",
    "        \n",
    "        for similar_user_idx in similar_users:\n",
    "            similarity = user_similarities[similar_user_idx]\n",
    "            similar_user_items = self.user_item_matrix[similar_user_idx].toarray()[0]\n",
    "            \n",
    "            # Items que l'utilisateur cible n'a pas encore écoutés\n",
    "            unseen_items = (user_items == 0) & (similar_user_items > 0)\n",
    "            recommendations[unseen_items] += similarity * similar_user_items[unseen_items]\n",
    "        \n",
    "        # Sélectionner top-N recommandations\n",
    "        top_items = np.argsort(recommendations)[::-1][:n_recommendations]\n",
    "        \n",
    "        return self._format_recommendations(top_items, recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22ceb5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemBasedCF:\n",
    "    def __init__(self, user_item_matrix, preprocessor):\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.preprocessor = preprocessor\n",
    "        self.item_similarity_matrix = None\n",
    "    \n",
    "    def compute_item_similarity(self, metric='cosine'):\n",
    "        \"\"\"Calcule la matrice de similarité entre items\"\"\"\n",
    "        from sklearn.metrics.pairwise import cosine_similarity\n",
    "        \n",
    "        # Transposer la matrice pour avoir items x users\n",
    "        item_user_matrix = self.user_item_matrix.T\n",
    "        self.item_similarity_matrix = cosine_similarity(item_user_matrix)\n",
    "        return self.item_similarity_matrix\n",
    "    \n",
    "    def recommend_for_item(self, song_id, n_recommendations=10):\n",
    "        \"\"\"Génère des recommandations pour un item donné\"\"\"\n",
    "        if song_id not in self.preprocessor.song_to_idx:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        item_idx = self.preprocessor.song_to_idx[song_id]\n",
    "        item_similarities = self.item_similarity_matrix[item_idx]\n",
    "        \n",
    "        # Exclure l'item lui-même et sélectionner les plus similaires\n",
    "        similar_items = np.argsort(item_similarities)[::-1][1:n_recommendations+1]\n",
    "        \n",
    "        return self._format_item_recommendations(similar_items, item_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45adb3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderEvaluator:\n",
    "    def __init__(self, user_item_matrix, test_ratio=0.2):\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.test_ratio = test_ratio\n",
    "        self.train_matrix = None\n",
    "        self.test_matrix = None\n",
    "    \n",
    "    def create_train_test_split(self):\n",
    "        \"\"\"Crée un split train/test en masquant aléatoirement des interactions\"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Copier la matrice originale\n",
    "        train_matrix = self.user_item_matrix.copy()\n",
    "        test_matrix = self.user_item_matrix.copy()\n",
    "        test_matrix.data = np.zeros_like(test_matrix.data)\n",
    "        \n",
    "        # Pour chaque utilisateur, masquer un pourcentage d'interactions\n",
    "        for user_idx in range(self.user_item_matrix.shape[0]):\n",
    "            user_items = self.user_item_matrix[user_idx].nonzero()[1]\n",
    "            \n",
    "            if len(user_items) > 1:  # Au moins 2 interactions\n",
    "                n_test = max(1, int(len(user_items) * self.test_ratio))\n",
    "                test_items = np.random.choice(user_items, n_test, replace=False)\n",
    "                \n",
    "                # Masquer dans train, révéler dans test\n",
    "                for item_idx in test_items:\n",
    "                    test_matrix[user_idx, item_idx] = train_matrix[user_idx, item_idx]\n",
    "                    train_matrix[user_idx, item_idx] = 0\n",
    "        \n",
    "        self.train_matrix = train_matrix.eliminate_zeros()\n",
    "        self.test_matrix = test_matrix.eliminate_zeros()\n",
    "        \n",
    "        return self.train_matrix, self.test_matrix\n",
    "    \n",
    "    def evaluate_precision_at_k(self, recommendations_dict, k=10):\n",
    "        \"\"\"Calcule la Precision@k moyenne\"\"\"\n",
    "        precisions = []\n",
    "        \n",
    "        for user_id, recommendations in recommendations_dict.items():\n",
    "            if user_id not in self.preprocessor.user_to_idx:\n",
    "                continue\n",
    "            \n",
    "            user_idx = self.preprocessor.user_to_idx[user_id]\n",
    "            actual_items = set(self.test_matrix[user_idx].nonzero()[1])\n",
    "            \n",
    "            if len(actual_items) == 0:\n",
    "                continue  # Pas d'items de test pour cet utilisateur\n",
    "            \n",
    "            # Extraire les k premiers items recommandés\n",
    "            recommended_items = set([\n",
    "                self.preprocessor.song_to_idx[rec['song_id']] \n",
    "                for rec in recommendations[:k]\n",
    "                if rec['song_id'] in self.preprocessor.song_to_idx\n",
    "            ])\n",
    "            \n",
    "            # Calculer precision\n",
    "            hits = len(recommended_items.intersection(actual_items))\n",
    "            precision = hits / k\n",
    "            precisions.append(precision)\n",
    "        \n",
    "        return np.mean(precisions) if precisions else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54268471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure modulaire recommandée\n",
    "\n",
    "class MySpotifyRecommender:\n",
    "    \"\"\"Classe principale orchestrant tous les types de recommandations\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        self.data_loader = DataLoader(data_path)\n",
    "        self.preprocessor = DataPreprocessor()\n",
    "        self.popularity_recommender = None\n",
    "        self.genre_recommender = None\n",
    "        self.thematic_recommender = None\n",
    "        self.user_cf = None\n",
    "        self.item_cf = None\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"Initialise tous les composants\"\"\"\n",
    "        # Chargement des données\n",
    "        triplets_df = self.data_loader.load_triplets()\n",
    "        tracks_df = self.data_loader.load_tracks()\n",
    "        lyrics_df = self.data_loader.load_lyrics()\n",
    "        genre_df = self.data_loader.load_genres()\n",
    "        \n",
    "        # Preprocessing\n",
    "        self.preprocessor.create_mappings(triplets_df)\n",
    "        user_item_matrix = self.preprocessor.build_user_item_matrix(triplets_df)\n",
    "        \n",
    "        # Initialisation des recommandeurs\n",
    "        self.popularity_recommender = PopularityRecommender(tracks_df, triplets_df)\n",
    "        self.genre_recommender = GenreRecommender(tracks_df, triplets_df, genre_df)\n",
    "        self.thematic_recommender = ThematicCollections(lyrics_df, tracks_df, triplets_df)\n",
    "        self.user_cf = UserBasedCF(user_item_matrix, self.preprocessor)\n",
    "        self.item_cf = ItemBasedCF(user_item_matrix, self.preprocessor)\n",
    "    \n",
    "    def get_top_tracks(self, n=250):\n",
    "        \"\"\"Interface pour les top tracks\"\"\"\n",
    "        return self.popularity_recommender.get_top_tracks(n)\n",
    "    \n",
    "    def get_top_by_genre(self, genre, n=100):\n",
    "        \"\"\"Interface pour les top par genre\"\"\"\n",
    "        return self.genre_recommender.get_top_by_genre(genre, n)\n",
    "    \n",
    "    def get_thematic_collection(self, theme, n=50, method='baseline'):\n",
    "        \"\"\"Interface pour les collections thématiques\"\"\"\n",
    "        if not self.thematic_recommender:\n",
    "            logger.error(\"Recommandeur thématique non initialisé\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        themes = {\n",
    "            'love': ['love', 'heart', 'kiss', 'romance'],\n",
    "            'war': ['war', 'fight', 'battle', 'soldier'],\n",
    "            'happiness': ['happy', 'joy', 'smile', 'laugh'],\n",
    "            'loneliness': ['alone', 'lonely', 'silence', 'empty'],\n",
    "            'money': ['money', 'rich', 'gold', 'dollar']\n",
    "        }\n",
    "        \n",
    "        if theme not in themes:\n",
    "            logger.error(f\"Thème {theme} non supporté\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        return self.thematic_recommender.get_thematic_collection(\n",
    "            themes[theme], \n",
    "            n=n, \n",
    "            method=method\n",
    "        )\n",
    "    \n",
    "    def get_similar_users_recommendations(self, user_id, n=10):\n",
    "        \"\"\"Interface pour les recommandations basées sur les utilisateurs similaires\"\"\"\n",
    "        if not self.user_cf:\n",
    "            logger.error(\"Recommandeur collaboratif utilisateurs non initialisé\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        if not self.user_cf.user_similarity_matrix:\n",
    "            self.user_cf.compute_user_similarity()\n",
    "            \n",
    "        return self.user_cf.recommend_for_user(user_id, n_recommendations=n)\n",
    "    \n",
    "    def get_similar_tracks_recommendations(self, song_id, n=10):\n",
    "        \"\"\"Interface pour les recommandations basées sur les morceaux similaires\"\"\"\n",
    "        if not self.item_cf:\n",
    "            logger.error(\"Recommandeur collaboratif items non initialisé\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        if not self.item_cf.item_similarity_matrix:\n",
    "            self.item_cf.compute_item_similarity()\n",
    "            \n",
    "        return self.item_cf.recommend_for_item(song_id, n_recommendations=n)\n",
    "    \n",
    "    def evaluate_recommendations(self, test_ratio=0.2, k=10):\n",
    "        \"\"\"Interface pour l'évaluation des recommandations\"\"\"\n",
    "        if not self.user_cf or not self.item_cf:\n",
    "            logger.error(\"Recommandeurs non initialisés\")\n",
    "            return {}\n",
    "            \n",
    "        evaluator = RecommenderEvaluator(\n",
    "            self.preprocessor.user_item_matrix, \n",
    "            test_ratio=test_ratio\n",
    "        )\n",
    "        \n",
    "        # Split train/test\n",
    "        train_matrix, test_matrix = evaluator.create_train_test_split()\n",
    "        \n",
    "        # Évaluer les recommandations utilisateurs\n",
    "        user_recommendations = {}\n",
    "        for user_id in list(self.preprocessor.user_to_idx.keys())[:100]:  # Échantillon pour test\n",
    "            recs = self.get_similar_users_recommendations(user_id, k)\n",
    "            if not recs.empty:\n",
    "                user_recommendations[user_id] = recs\n",
    "        \n",
    "        # Évaluer les recommandations items\n",
    "        item_recommendations = {}\n",
    "        for song_id in list(self.preprocessor.song_to_idx.keys())[:100]:  # Échantillon pour test\n",
    "            recs = self.get_similar_tracks_recommendations(song_id, k)\n",
    "            if not recs.empty:\n",
    "                item_recommendations[song_id] = recs\n",
    "                \n",
    "        results = {\n",
    "            'user_precision@k': evaluator.evaluate_precision_at_k(user_recommendations, k),\n",
    "            'item_precision@k': evaluator.evaluate_precision_at_k(item_recommendations, k)\n",
    "        }\n",
    "        \n",
    "        logger.info(f\"Résultats d'évaluation: {results}\")\n",
    "        return results\n",
    "\n",
    "    def get_all_recommendations(self, user_id):\n",
    "        \"\"\"Interface pour obtenir toutes les recommandations pour un utilisateur\"\"\"\n",
    "        results = {\n",
    "            'top_tracks': self.get_top_tracks(n=10),\n",
    "            'user_based': self.get_similar_users_recommendations(user_id, n=10),\n",
    "            'thematic': {\n",
    "                'love': self.get_thematic_collection('love', n=5),\n",
    "                'happiness': self.get_thematic_collection('happiness', n=5)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Ajouter les recommandations par genre\n",
    "        genres = ['Rock', 'Rap', 'Jazz', 'Electronic', 'Pop', \n",
    "                 'Blues', 'Country', 'Reggae', 'New Age']\n",
    "        results['by_genre'] = {\n",
    "            genre: self.get_top_by_genre(genre, n=5) \n",
    "            for genre in genres\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    # ... autres méthodes d'interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b5e80a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationException(Exception):\n",
    "    \"\"\"Exception personnalisée pour les erreurs de recommandation\"\"\"\n",
    "    pass\n",
    "\n",
    "def safe_recommend(func):\n",
    "    \"\"\"Décorateur pour gérer les erreurs de recommandation\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except KeyError as e:\n",
    "            logger.warning(f\"Clé non trouvée: {e}\")\n",
    "            return pd.DataFrame()  # Retour par défaut\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Erreur dans {func.__name__}: {e}\")\n",
    "            raise RecommendationException(f\"Erreur de recommandation: {e}\")\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b323b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'optimisation mémoire pour gros datasets\n",
    "def compute_similarity_chunked(matrix, chunk_size=1000):\n",
    "    \"\"\"Calcule la similarité par chunks pour éviter OOM\"\"\"\n",
    "    n_items = matrix.shape[0]\n",
    "    similarity_matrix = np.zeros((n_items, n_items))\n",
    "    \n",
    "    for i in range(0, n_items, chunk_size):\n",
    "        end_i = min(i + chunk_size, n_items)\n",
    "        chunk_i = matrix[i:end_i]\n",
    "        \n",
    "        for j in range(0, n_items, chunk_size):\n",
    "            end_j = min(j + chunk_size, n_items)\n",
    "            chunk_j = matrix[j:end_j]\n",
    "            \n",
    "            similarity_matrix[i:end_i, j:end_j] = cosine_similarity(chunk_i, chunk_j)\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6940f268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscoverWeekly:\n",
    "    def __init__(self, user_cf, content_cf, popularity_cf):\n",
    "        self.user_cf = user_cf\n",
    "        self.content_cf = content_cf  \n",
    "        self.popularity_cf = popularity_cf\n",
    "    \n",
    "    def generate_playlist(self, user_id, n_tracks=30):\n",
    "        \"\"\"Génère une playlist découverte personnalisée\"\"\"\n",
    "        # 40% collaborative filtering\n",
    "        cf_recs = self.user_cf.recommend_for_user(user_id, n_tracks//2)\n",
    "        \n",
    "        # 30% content-based sur artistes similaires\n",
    "        user_artists = self._get_user_top_artists(user_id)\n",
    "        content_recs = self.content_cf.recommend_similar_artists(user_artists)\n",
    "        \n",
    "        # 30% découverte (popularité récente + diversité)\n",
    "        discovery_recs = self.popularity_cf.get_trending_tracks(\n",
    "            exclude_user_history=user_id\n",
    "        )\n",
    "        \n",
    "        # Mélange pondéré avec diversification\n",
    "        return self._blend_and_diversify([cf_recs, content_recs, discovery_recs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6995791",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArtistRadio:\n",
    "    def __init__(self, content_analyzer, collaborative_filter):\n",
    "        self.content_analyzer = content_analyzer\n",
    "        self.collaborative_filter = collaborative_filter\n",
    "    \n",
    "    def create_artist_radio(self, seed_artist, n_tracks=50):\n",
    "        \"\"\"Crée une radio basée sur un artiste seed\"\"\"\n",
    "        # Analyser le profil musical de l'artiste\n",
    "        artist_profile = self.content_analyzer.get_artist_profile(seed_artist)\n",
    "        \n",
    "        # Expansion par genres/sous-genres\n",
    "        similar_genre_artists = self._find_genre_expansion(artist_profile)\n",
    "        \n",
    "        # Expansion collaborative (artistes co-écoutés)\n",
    "        collab_artists = self.collaborative_filter.find_colistened_artists(seed_artist)\n",
    "        \n",
    "        # Diversification temporelle et énergétique\n",
    "        return self._create_radio_flow(seed_artist, similar_genre_artists, collab_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36186365",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonalizedPlaylists:\n",
    "    def __init__(self):\n",
    "        self.user_profiler = UserMoodProfiler()\n",
    "        self.temporal_analyzer = TemporalAnalyzer()\n",
    "    \n",
    "    def generate_mood_playlist(self, user_id, time_of_day, context=\"workout\"):\n",
    "        \"\"\"Génère une playlist adaptée au contexte\"\"\"\n",
    "        # Analyser l'historique temporel de l'utilisateur\n",
    "        temporal_prefs = self.temporal_analyzer.get_time_preferences(user_id, time_of_day)\n",
    "        \n",
    "        # Profil émotionnel basé sur les paroles\n",
    "        mood_profile = self.user_profiler.extract_mood_from_lyrics(user_id)\n",
    "        \n",
    "        # Adaptation contextuelle\n",
    "        context_tracks = self._get_context_appropriate_tracks(\n",
    "            context, temporal_prefs, mood_profile\n",
    "        )\n",
    "        \n",
    "        return self._optimize_playlist_flow(context_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cc49da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedMetrics:\n",
    "    @staticmethod\n",
    "    def calculate_diversity(recommendations):\n",
    "        \"\"\"Mesure la diversité intra-liste des recommandations\"\"\"\n",
    "        # Diversité de genres, d'artistes, d'années, etc.\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_novelty(recommendations, user_history):\n",
    "        \"\"\"Mesure la nouveauté par rapport à l'historique utilisateur\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_serendipity(recommendations, expected_items):\n",
    "        \"\"\"Mesure l'effet de surprise positif\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf0556e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VÉRIFICATION DES FICHIERS ===\n",
      "✅ train_triplets.txt (Triplets (user_id, song_id, play_count)) - 2862.6 MB\n",
      "✅ p02_unique_tracks.txt (Informations des tracks) - 80.2 MB\n",
      "✅ mxm_dataset_train.txt (Données de paroles) - 98.0 MB\n",
      "✅ p02_msd_tagtraum_cd2.cls (Genres musicaux) - 7.1 MB\n",
      "\n",
      "=== EXPLORATION RAPIDE ===\n",
      "Triplets - Exemple:\n",
      "                                    user_id             song_id  play_count\n",
      "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAKIMP12A8C130995           1\n",
      "1  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOAPDEY12A81C210A9           1\n",
      "2  b80344d063b5ccb3212f76538f3d9e43d87dca9e  SOBBMDR12A8C13253B           2\n",
      "Shape: (1000, 3)\n",
      "Users uniques: 13\n",
      "Songs uniques: 951\n",
      "\n",
      "Tracks - Exemple:\n",
      "             track_id             song_id            artist              title\n",
      "0  TRMMMYQ128F932D901  SOQMMHC12AB0180CB8  Faster Pussy cat       Silent Night\n",
      "1  TRMMMKD128F425225D  SOVFVAK12A8C1350D9  Karkkiautomaatti        Tanssi vaan\n",
      "2  TRMMMRX128F93187D9  SOGTUKN12AB017F4F1    Hudson Mohawke  No One Could Ever\n",
      "Shape: (100, 4)\n",
      "\n",
      "Genres - Exemple:\n",
      "TRAAAAK128F9318786\tRock\n",
      "TRAAAAW128F429D538\tRap\n",
      "TRAAABD128F429CF47\tRock\tRnB\n",
      "\n",
      "Paroles - Exemple:\n",
      "\n",
      "=== ESTIMATION MÉMOIRE ===\n",
      "Triplets: ~48,373,586 lignes\n",
      "Mémoire estimée: ~3690.6 MB\n",
      "⚠️  Dataset moyen-volumineux, monitoring mémoire recommandé\n"
     ]
    }
   ],
   "source": [
    "# data_check.py - Script pour vérifier la qualité des données\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def check_data_files():\n",
    "    \"\"\"Vérifie que tous les fichiers de données sont présents et lisibles\"\"\"\n",
    "    \n",
    "    data_files = {\n",
    "        'train_triplets.txt': 'Triplets (user_id, song_id, play_count)',\n",
    "        'p02_unique_tracks.txt': 'Informations des tracks',\n",
    "        'mxm_dataset_train.txt': 'Données de paroles',\n",
    "        'p02_msd_tagtraum_cd2.cls': 'Genres musicaux'\n",
    "    }\n",
    "    \n",
    "    print(\"=== VÉRIFICATION DES FICHIERS ===\")\n",
    "    for filename, description in data_files.items():\n",
    "        filepath = Path(filename)\n",
    "        if filepath.exists():\n",
    "            size_mb = filepath.stat().st_size / (1024 * 1024)\n",
    "            print(f\"✅ {filename} ({description}) - {size_mb:.1f} MB\")\n",
    "        else:\n",
    "            print(f\"❌ {filename} - MANQUANT\")\n",
    "    print()\n",
    "\n",
    "def quick_data_exploration():\n",
    "    \"\"\"Exploration rapide des données\"\"\"\n",
    "    \n",
    "    print(\"=== EXPLORATION RAPIDE ===\")\n",
    "    \n",
    "    # Triplets\n",
    "    try:\n",
    "        triplets = pd.read_csv('train_triplets.txt', sep='\\t', \n",
    "                              names=['user_id', 'song_id', 'play_count'], \n",
    "                              nrows=1000)  # Lire seulement 1000 lignes pour test\n",
    "        print(f\"Triplets - Exemple:\")\n",
    "        print(triplets.head(3))\n",
    "        print(f\"Shape: {triplets.shape}\")\n",
    "        print(f\"Users uniques: {triplets['user_id'].nunique()}\")\n",
    "        print(f\"Songs uniques: {triplets['song_id'].nunique()}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur triplets: {e}\")\n",
    "    \n",
    "    # Tracks\n",
    "    try:\n",
    "        tracks = pd.read_csv('p02_unique_tracks.txt', sep='<SEP>', \n",
    "                            names=['track_id', 'song_id', 'artist', 'title'],\n",
    "                            engine='python', nrows=100)\n",
    "        print(f\"Tracks - Exemple:\")\n",
    "        print(tracks.head(3))\n",
    "        print(f\"Shape: {tracks.shape}\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur tracks: {e}\")\n",
    "    \n",
    "    # Genres\n",
    "    try:\n",
    "        with open('p02_msd_tagtraum_cd2.cls', 'r') as f:\n",
    "            lines = [line.strip() for line in f.readlines()[:10] if line.strip() and not line.startswith('#')]\n",
    "        \n",
    "        print(\"Genres - Exemple:\")\n",
    "        for line in lines[:5]:\n",
    "            print(line)\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur genres: {e}\")\n",
    "    \n",
    "    # Paroles\n",
    "    try:\n",
    "        with open('mxm_dataset_train.txt', 'r') as f:\n",
    "            lines = [line.strip() for line in f.readlines()[:20]]\n",
    "        \n",
    "        print(\"Paroles - Exemple:\")\n",
    "        for line in lines[:5]:\n",
    "            if not line.startswith('#'):\n",
    "                print(line[:100] + \"...\" if len(line) > 100 else line)\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur paroles: {e}\")\n",
    "\n",
    "def estimate_memory_usage():\n",
    "    \"\"\"Estime l'usage mémoire\"\"\"\n",
    "    \n",
    "    print(\"=== ESTIMATION MÉMOIRE ===\")\n",
    "    \n",
    "    try:\n",
    "        # Compter les lignes des triplets\n",
    "        with open('train_triplets.txt', 'r') as f:\n",
    "            line_count = sum(1 for line in f)\n",
    "        \n",
    "        # Estimation: ~50-100 bytes par ligne en mémoire\n",
    "        estimated_mb = (line_count * 80) / (1024 * 1024)\n",
    "        print(f\"Triplets: ~{line_count:,} lignes\")\n",
    "        print(f\"Mémoire estimée: ~{estimated_mb:.1f} MB\")\n",
    "        \n",
    "        if estimated_mb > 4000:  # Plus de 4GB\n",
    "            print(\"⚠️  ATTENTION: Dataset très volumineux!\")\n",
    "            print(\"   Considérez utiliser des chunks pour le chargement\")\n",
    "        elif estimated_mb > 1000:  # Plus de 1GB\n",
    "            print(\"⚠️  Dataset moyen-volumineux, monitoring mémoire recommandé\")\n",
    "        else:\n",
    "            print(\"✅ Taille de dataset gérable\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur estimation: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_data_files()\n",
    "    quick_data_exploration()\n",
    "    estimate_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5ce9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 21:02:42,117 - INFO - === PHASE 1: CHARGEMENT DES DONNÉES ===\n",
      "2025-08-23 21:02:42,120 - INFO - Chargement des triplets depuis train_triplets.txt...\n",
      "2025-08-23 21:03:01,580 - INFO - Triplets chargés: 48373586 interactions\n",
      "2025-08-23 21:03:01,588 - INFO - Chargement des tracks depuis p02_unique_tracks.txt...\n",
      "2025-08-23 21:03:03,315 - INFO - Tracks chargés: 1000000 pistes\n",
      "2025-08-23 21:03:03,315 - INFO - Chargement des paroles depuis mxm_dataset_train.txt...\n",
      "2025-08-23 21:03:07,239 - INFO - Paroles chargées: 210519 pistes avec paroles\n",
      "2025-08-23 21:03:07,256 - INFO - Chargement des genres depuis p02_msd_tagtraum_cd2.cls...\n",
      "2025-08-23 21:03:07,480 - INFO - Genres chargés: 280831 pistes avec genres\n",
      "2025-08-23 21:03:07,494 - INFO - === PHASE 2: PREPROCESSING ===\n",
      "2025-08-23 21:03:07,495 - INFO - Création des mappings user/song...\n",
      "2025-08-23 21:03:17,164 - INFO - Mappings créés: 1019318 users, 384546 songs\n",
      "2025-08-23 21:03:17,177 - INFO - Construction de la matrice user-item...\n",
      "2025-08-23 21:03:25,681 - INFO - Matrice construite: (1019318, 384546), sparsité: 0.9999\n",
      "2025-08-23 21:03:25,699 - INFO - === PHASE 3: RECOMMANDATIONS NON-PERSONNALISÉES ===\n",
      "2025-08-23 21:03:25,700 - INFO - Génération du top-250 tracks...\n",
      "2025-08-23 21:03:38,952 - INFO - Top-250 généré avec 250 tracks\n",
      "2025-08-23 21:03:39,219 - INFO - Génération du top-10 pour le genre Rock...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 des tracks les plus populaires:\n",
      "   index                                             artist  \\\n",
      "0      1                                      Dwight Yoakam   \n",
      "1      2                                              Björk   \n",
      "2      3                                      Kings Of Leon   \n",
      "3      4                                           Harmonia   \n",
      "4      5  Barry Tuckwell/Academy of St Martin-in-the-Fie...   \n",
      "5      6                             Florence + The Machine   \n",
      "6      7                                        OneRepublic   \n",
      "7      8                                   Five Iron Frenzy   \n",
      "8      9                                           Tub Ring   \n",
      "9     10                                          Sam Cooke   \n",
      "\n",
      "                                               title  play_count  \n",
      "0                                     You're The One      726885  \n",
      "1                                               Undo      648239  \n",
      "2                                            Revelry      527893  \n",
      "3                                      Sehr kosmisch      425463  \n",
      "4  Horn Concerto No. 4 in E flat K495: II. Romanc...      389880  \n",
      "5                     Dog Days Are Over (Radio Edit)      356533  \n",
      "6                                            Secrets      292642  \n",
      "7                                             Canada      274627  \n",
      "8                                            Invalid      268353  \n",
      "9                                   Ain't Misbehavin      244730  \n",
      "\n",
      "Genres disponibles: ['Rock' 'Rap' 'Latin' 'Jazz' 'Electronic' 'Punk' 'Pop' 'New Age' 'Metal'\n",
      " 'RnB' 'Country' 'Reggae' 'Folk' 'Blues' 'World']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 21:03:46,035 - INFO - Top-10 Rock généré avec 10 tracks\n",
      "2025-08-23 21:03:46,637 - INFO - === STATISTIQUES GÉNÉRALES ===\n",
      "2025-08-23 21:03:46,637 - INFO - === SAUVEGARDE ===\n",
      "2025-08-23 21:03:46,649 - INFO - Résultats sauvegardés dans top_250_tracks.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Rock:\n",
      "   index         artist                               title  play_count\n",
      "0      1          Björk                                Undo      648239\n",
      "1      2  Kings Of Leon                             Revelry      527893\n",
      "2      3       Harmonia                       Sehr kosmisch      425463\n",
      "3      4    OneRepublic                             Secrets      292642\n",
      "4      5       Tub Ring                             Invalid      268353\n",
      "5      6  Kings Of Leon                        Use Somebody      145725\n",
      "6      7     The Crests                          16 Candles      129069\n",
      "7      8       Coldplay                              Clocks      114362\n",
      "8      9       Coldplay                              Yellow      109566\n",
      "9     10       Paramore  The Only Exception (Album Version)      103653\n",
      "Nombre total d'utilisateurs: 1019318\n",
      "Nombre total de chansons: 384546\n",
      "Nombre total d'interactions: 48373586\n",
      "Sparsité de la matrice: 0.999877\n"
     ]
    }
   ],
   "source": [
    "# main.py - Script principal pour tester MySpotify\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"Classe pour charger tous les datasets\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = Path(data_path)\n",
    "    \n",
    "    def load_triplets(self, filename=\"train_triplets.txt\"):\n",
    "        \"\"\"Charge les triplets (user_id, song_id, play_count)\"\"\"\n",
    "        logger.info(f\"Chargement des triplets depuis {filename}...\")\n",
    "        filepath = self.data_path / filename\n",
    "        \n",
    "        df = pd.read_csv(filepath, sep='\\t', \n",
    "                        names=['user_id', 'song_id', 'play_count'])\n",
    "        logger.info(f\"Triplets chargés: {len(df)} interactions\")\n",
    "        return df\n",
    "    \n",
    "    def load_tracks(self, filename=\"p02_unique_tracks.txt\"):\n",
    "        \"\"\"Charge les informations des tracks\"\"\"\n",
    "        logger.info(f\"Chargement des tracks depuis {filename}...\")\n",
    "        filepath = self.data_path / filename\n",
    "        \n",
    "        df = pd.read_csv(filepath, sep='<SEP>', \n",
    "                        names=['track_id', 'song_id', 'artist', 'title'],\n",
    "                        engine='python')\n",
    "        logger.info(f\"Tracks chargés: {len(df)} pistes\")\n",
    "        return df\n",
    "    \n",
    "    def load_lyrics(self, filename=\"mxm_dataset_train.txt\"):\n",
    "        \"\"\"Charge les données de paroles\"\"\"\n",
    "        logger.info(f\"Chargement des paroles depuis {filename}...\")\n",
    "        filepath = self.data_path / filename\n",
    "        \n",
    "        lyrics_data = []\n",
    "        word_mapping = {}\n",
    "        \n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                \n",
    "                # Skip comments\n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                \n",
    "                # Get word mapping\n",
    "                if line.startswith('%'):\n",
    "                    words = line[1:].split(',')\n",
    "                    word_mapping = {i+1: word for i, word in enumerate(words)}\n",
    "                    continue\n",
    "                \n",
    "                # Parse lyrics data\n",
    "                if line:\n",
    "                    parts = line.split(',')\n",
    "                    track_id = parts[0]\n",
    "                    mxm_track_id = parts[1]\n",
    "                    \n",
    "                    word_counts = {}\n",
    "                    for part in parts[2:]:\n",
    "                        if ':' in part:\n",
    "                            word_idx, count = part.split(':')\n",
    "                            word_counts[int(word_idx)] = int(count)\n",
    "                    \n",
    "                    lyrics_data.append({\n",
    "                        'track_id': track_id,\n",
    "                        'mxm_track_id': mxm_track_id,\n",
    "                        'word_counts': word_counts\n",
    "                    })\n",
    "        \n",
    "        df = pd.DataFrame(lyrics_data)\n",
    "        logger.info(f\"Paroles chargées: {len(df)} pistes avec paroles\")\n",
    "        return df, word_mapping\n",
    "    \n",
    "    def load_genres(self, filename=\"p02_msd_tagtraum_cd2.cls\"):\n",
    "        \"\"\"Charge les genres\"\"\"\n",
    "        logger.info(f\"Chargement des genres depuis {filename}...\")\n",
    "        filepath = self.data_path / filename\n",
    "        \n",
    "        genres_data = []\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    parts = line.split('\\t')\n",
    "                    track_id = parts[0]\n",
    "                    majority_genre = parts[1]\n",
    "                    minority_genre = parts[2] if len(parts) > 2 else None\n",
    "                    \n",
    "                    genres_data.append({\n",
    "                        'track_id': track_id,\n",
    "                        'majority_genre': majority_genre,\n",
    "                        'minority_genre': minority_genre\n",
    "                    })\n",
    "        \n",
    "        df = pd.DataFrame(genres_data)\n",
    "        logger.info(f\"Genres chargés: {len(df)} pistes avec genres\")\n",
    "        return df\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Classe pour préprocesser les données\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.user_to_idx = {}\n",
    "        self.song_to_idx = {}\n",
    "        self.idx_to_user = {}\n",
    "        self.idx_to_song = {}\n",
    "    \n",
    "    def create_mappings(self, triplets_df):\n",
    "        \"\"\"Crée les mappings bidirectionnels\"\"\"\n",
    "        logger.info(\"Création des mappings user/song...\")\n",
    "        \n",
    "        unique_users = triplets_df['user_id'].unique()\n",
    "        unique_songs = triplets_df['song_id'].unique()\n",
    "        \n",
    "        self.user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.song_to_idx = {song: idx for idx, song in enumerate(unique_songs)}\n",
    "        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}\n",
    "        self.idx_to_song = {idx: song for song, idx in self.song_to_idx.items()}\n",
    "        \n",
    "        logger.info(f\"Mappings créés: {len(self.user_to_idx)} users, {len(self.song_to_idx)} songs\")\n",
    "    \n",
    "    def build_user_item_matrix(self, triplets_df):\n",
    "        \"\"\"Construit la matrice user-item sparse\"\"\"\n",
    "        logger.info(\"Construction de la matrice user-item...\")\n",
    "        \n",
    "        user_indices = triplets_df['user_id'].map(self.user_to_idx)\n",
    "        song_indices = triplets_df['song_id'].map(self.song_to_idx)\n",
    "        play_counts = triplets_df['play_count']\n",
    "        \n",
    "        matrix = csr_matrix(\n",
    "            (play_counts, (user_indices, song_indices)),\n",
    "            shape=(len(self.user_to_idx), len(self.song_to_idx))\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Matrice construite: {matrix.shape}, sparsité: {1 - matrix.nnz / np.prod(matrix.shape):.4f}\")\n",
    "        return matrix\n",
    "\n",
    "class PopularityRecommender:\n",
    "    \"\"\"Recommandeur basé sur la popularité\"\"\"\n",
    "    \n",
    "    def __init__(self, tracks_df, triplets_df):\n",
    "        self.tracks_df = tracks_df\n",
    "        self.triplets_df = triplets_df\n",
    "    \n",
    "    def get_top_tracks(self, n=250):\n",
    "        \"\"\"Retourne les n tracks les plus populaires\"\"\"\n",
    "        logger.info(f\"Génération du top-{n} tracks...\")\n",
    "        \n",
    "        # Calculer la popularité globale\n",
    "        popularity = self.triplets_df.groupby('song_id')['play_count'].sum().sort_values(ascending=False)\n",
    "        top_songs = popularity.head(n)\n",
    "        \n",
    "        results = []\n",
    "        for i, (song_id, play_count) in enumerate(top_songs.items(), 1):\n",
    "            # Trouver les infos du track\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            if not track_info.empty:\n",
    "                track_info = track_info.iloc[0]\n",
    "                results.append({\n",
    "                    'index': i,\n",
    "                    'artist': track_info['artist'],\n",
    "                    'title': track_info['title'],\n",
    "                    'song_id': song_id,\n",
    "                    'play_count': int(play_count)\n",
    "                })\n",
    "        \n",
    "        df_result = pd.DataFrame(results)\n",
    "        logger.info(f\"Top-{n} généré avec {len(df_result)} tracks\")\n",
    "        return df_result\n",
    "\n",
    "class GenreRecommender:\n",
    "    \"\"\"Recommandeur basé sur les genres\"\"\"\n",
    "    \n",
    "    def __init__(self, tracks_df, triplets_df, genre_df):\n",
    "        self.tracks_df = tracks_df\n",
    "        self.triplets_df = triplets_df\n",
    "        self.genre_df = genre_df\n",
    "    \n",
    "    def get_top_by_genre(self, genre, n=100):\n",
    "        \"\"\"Retourne les n tracks les plus populaires pour un genre\"\"\"\n",
    "        logger.info(f\"Génération du top-{n} pour le genre {genre}...\")\n",
    "        \n",
    "        # Filtrer par genre\n",
    "        genre_tracks = self.genre_df[\n",
    "            self.genre_df['majority_genre'] == genre\n",
    "        ]['track_id'].values\n",
    "        \n",
    "        # Mapper track_id vers song_id\n",
    "        genre_songs = self.tracks_df[\n",
    "            self.tracks_df['track_id'].isin(genre_tracks)\n",
    "        ]['song_id'].values\n",
    "        \n",
    "        # Calculer popularité dans ce genre\n",
    "        genre_triplets = self.triplets_df[\n",
    "            self.triplets_df['song_id'].isin(genre_songs)\n",
    "        ]\n",
    "        \n",
    "        if genre_triplets.empty:\n",
    "            logger.warning(f\"Aucune chanson trouvée pour le genre {genre}\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        popularity = genre_triplets.groupby('song_id')['play_count'].sum().sort_values(ascending=False)\n",
    "        top_songs = popularity.head(n)\n",
    "        \n",
    "        results = []\n",
    "        for i, (song_id, play_count) in enumerate(top_songs.items(), 1):\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            if not track_info.empty:\n",
    "                track_info = track_info.iloc[0]\n",
    "                results.append({\n",
    "                    'index': i,\n",
    "                    'genre': genre,\n",
    "                    'artist': track_info['artist'],\n",
    "                    'title': track_info['title'],\n",
    "                    'song_id': song_id,\n",
    "                    'play_count': int(play_count)\n",
    "                })\n",
    "        \n",
    "        df_result = pd.DataFrame(results)\n",
    "        logger.info(f\"Top-{n} {genre} généré avec {len(df_result)} tracks\")\n",
    "        return df_result\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale pour tester le système\"\"\"\n",
    "    \n",
    "    # Configuration\n",
    "    DATA_PATH = \".\"  # Ajustez selon votre structure de dossiers\n",
    "    \n",
    "    try:\n",
    "        # 1. Chargement des données\n",
    "        logger.info(\"=== PHASE 1: CHARGEMENT DES DONNÉES ===\")\n",
    "        data_loader = DataLoader(DATA_PATH)\n",
    "        \n",
    "        triplets_df = data_loader.load_triplets()\n",
    "        tracks_df = data_loader.load_tracks()\n",
    "        lyrics_df, word_mapping = data_loader.load_lyrics()\n",
    "        genre_df = data_loader.load_genres()\n",
    "        \n",
    "        # 2. Preprocessing\n",
    "        logger.info(\"=== PHASE 2: PREPROCESSING ===\")\n",
    "        preprocessor = DataPreprocessor()\n",
    "        preprocessor.create_mappings(triplets_df)\n",
    "        user_item_matrix = preprocessor.build_user_item_matrix(triplets_df)\n",
    "        \n",
    "        # 3. Test des recommandeurs non-personnalisés\n",
    "        logger.info(\"=== PHASE 3: RECOMMANDATIONS NON-PERSONNALISÉES ===\")\n",
    "        \n",
    "        # Top-250 tracks\n",
    "        popularity_rec = PopularityRecommender(tracks_df, triplets_df)\n",
    "        top_250 = popularity_rec.get_top_tracks(250)\n",
    "        print(\"Top 10 des tracks les plus populaires:\")\n",
    "        print(top_250.head(10)[['index', 'artist', 'title', 'play_count']])\n",
    "        print()\n",
    "        \n",
    "        # Top-100 par genre\n",
    "        genre_rec = GenreRecommender(tracks_df, triplets_df, genre_df)\n",
    "        available_genres = genre_df['majority_genre'].unique()\n",
    "        print(f\"Genres disponibles: {available_genres}\")\n",
    "        \n",
    "        # Test avec le genre \"Rock\"\n",
    "        if 'Rock' in available_genres:\n",
    "            top_rock = genre_rec.get_top_by_genre('Rock', 10)\n",
    "            print(\"Top 10 Rock:\")\n",
    "            print(top_rock[['index', 'artist', 'title', 'play_count']])\n",
    "        \n",
    "        # 4. Statistiques générales\n",
    "        logger.info(\"=== STATISTIQUES GÉNÉRALES ===\")\n",
    "        print(f\"Nombre total d'utilisateurs: {len(preprocessor.user_to_idx)}\")\n",
    "        print(f\"Nombre total de chansons: {len(preprocessor.song_to_idx)}\")\n",
    "        print(f\"Nombre total d'interactions: {len(triplets_df)}\")\n",
    "        print(f\"Sparsité de la matrice: {1 - user_item_matrix.nnz / np.prod(user_item_matrix.shape):.6f}\")\n",
    "        \n",
    "        # 5. Sauvegarde des résultats\n",
    "        logger.info(\"=== SAUVEGARDE ===\")\n",
    "        top_250.to_csv('top_250_tracks.csv', index=False)\n",
    "        logger.info(\"Résultats sauvegardés dans top_250_tracks.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erreur lors de l'exécution: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1aa775a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TEST COLLABORATIVE FILTERING ===\n",
      "Chargement des données...\n",
      "Données chargées: 10000 interactions\n",
      "Matrice construite: (173, 7849)\n",
      "Sparsité: 0.9926\n",
      "\n",
      "Test pour l'utilisateur: b80344d063b5ccb3212f76538f3d9e43d87dca9e\n",
      "L'utilisateur a écouté 104 chansons différentes\n",
      "Calcul de similarité requis...\n",
      "Calcul de similarité pour 1000 premiers utilisateurs...\n",
      "Matrice de similarité calculée: (173, 173)\n",
      "\n",
      "Recommandations générées:\n",
      "1. SOAUWYT12A81C206F1 (score: 2.456)\n",
      "2. SOPUCYA12A8C13A694 (score: 1.214)\n",
      "3. SOQZYQH12A8AE468E5 (score: 0.903)\n",
      "4. SOTLEJN12A8C13E8EF (score: 0.815)\n",
      "5. SOPATZX12A8AE46295 (score: 0.815)\n",
      "\n",
      "✅ Test collaborative filtering terminé avec succès!\n"
     ]
    }
   ],
   "source": [
    "# test_collaborative_filtering.py - Test du Collaborative Filtering\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "\n",
    "class UserBasedCF:\n",
    "    \"\"\"Collaborative Filtering basé utilisateur simplifié\"\"\"\n",
    "    \n",
    "    def __init__(self, user_item_matrix, preprocessor):\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.preprocessor = preprocessor\n",
    "        self.user_similarity_matrix = None\n",
    "    \n",
    "    def compute_user_similarity(self, n_users=1000):\n",
    "        \"\"\"Calcule similarité pour un sous-ensemble d'utilisateurs\"\"\"\n",
    "        print(f\"Calcul de similarité pour {n_users} premiers utilisateurs...\")\n",
    "        \n",
    "        # Utiliser seulement un sous-ensemble pour éviter les problèmes mémoire\n",
    "        subset_matrix = self.user_item_matrix[:n_users, :]\n",
    "        \n",
    "        # Normalisation L2 pour cosine similarity\n",
    "        from sklearn.preprocessing import normalize\n",
    "        normalized_matrix = normalize(subset_matrix, norm='l2', axis=1)\n",
    "        \n",
    "        # Calcul de similarité\n",
    "        self.user_similarity_matrix = cosine_similarity(normalized_matrix)\n",
    "        print(f\"Matrice de similarité calculée: {self.user_similarity_matrix.shape}\")\n",
    "        \n",
    "        return self.user_similarity_matrix\n",
    "    \n",
    "    def recommend_for_user(self, user_idx, n_recommendations=10, n_neighbors=20):\n",
    "        \"\"\"Recommandations pour un utilisateur donné\"\"\"\n",
    "        \n",
    "        if self.user_similarity_matrix is None:\n",
    "            print(\"Calcul de similarité requis...\")\n",
    "            self.compute_user_similarity()\n",
    "        \n",
    "        if user_idx >= self.user_similarity_matrix.shape[0]:\n",
    "            print(f\"User index {user_idx} hors limite\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Trouver utilisateurs similaires\n",
    "        user_similarities = self.user_similarity_matrix[user_idx]\n",
    "        # Exclure l'utilisateur lui-même\n",
    "        user_similarities[user_idx] = -1\n",
    "        \n",
    "        # Top utilisateurs similaires\n",
    "        similar_users = np.argsort(user_similarities)[::-1][:n_neighbors]\n",
    "        \n",
    "        # Items de l'utilisateur cible\n",
    "        user_items = self.user_item_matrix[user_idx].toarray()[0]\n",
    "        recommendations = np.zeros(self.user_item_matrix.shape[1])\n",
    "        \n",
    "        # Calculer scores de recommandation\n",
    "        for similar_user_idx in similar_users:\n",
    "            if user_similarities[similar_user_idx] > 0:  # Similarité positive\n",
    "                similarity = user_similarities[similar_user_idx]\n",
    "                similar_user_items = self.user_item_matrix[similar_user_idx].toarray()[0]\n",
    "                \n",
    "                # Items non vus par l'utilisateur cible\n",
    "                unseen_items = (user_items == 0) & (similar_user_items > 0)\n",
    "                recommendations[unseen_items] += similarity * similar_user_items[unseen_items]\n",
    "        \n",
    "        # Sélectionner top recommendations\n",
    "        if recommendations.sum() == 0:\n",
    "            print(\"Aucune recommandation trouvée\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        top_items_idx = np.argsort(recommendations)[::-1][:n_recommendations]\n",
    "        top_scores = recommendations[top_items_idx]\n",
    "        \n",
    "        # Convertir en song_ids\n",
    "        results = []\n",
    "        for i, (item_idx, score) in enumerate(zip(top_items_idx, top_scores)):\n",
    "            if score > 0:\n",
    "                song_id = self.preprocessor.idx_to_song.get(item_idx, 'Unknown')\n",
    "                results.append({\n",
    "                    'rank': i + 1,\n",
    "                    'song_id': song_id,\n",
    "                    'score': float(score),\n",
    "                    'item_idx': int(item_idx)\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def test_collaborative_filtering():\n",
    "    \"\"\"Test du système de collaborative filtering\"\"\"\n",
    "    \n",
    "    print(\"=== TEST COLLABORATIVE FILTERING ===\")\n",
    "    \n",
    "    # Charger un petit échantillon de données pour test\n",
    "    print(\"Chargement des données...\")\n",
    "    try:\n",
    "        # Lire seulement les premières lignes pour test rapide\n",
    "        triplets_df = pd.read_csv('train_triplets.txt', sep='\\t', \n",
    "                                 names=['user_id', 'song_id', 'play_count'],\n",
    "                                 nrows=10000)  # Limiter pour test\n",
    "        \n",
    "        tracks_df = pd.read_csv('p02_unique_tracks.txt', sep='<SEP>', \n",
    "                               names=['track_id', 'song_id', 'artist', 'title'],\n",
    "                               engine='python', nrows=5000)\n",
    "        \n",
    "        print(f\"Données chargées: {len(triplets_df)} interactions\")\n",
    "        \n",
    "        # Créer mappings\n",
    "        unique_users = triplets_df['user_id'].unique()\n",
    "        unique_songs = triplets_df['song_id'].unique()\n",
    "        \n",
    "        user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        song_to_idx = {song: idx for idx, song in enumerate(unique_songs)}\n",
    "        idx_to_user = {idx: user for user, idx in user_to_idx.items()}\n",
    "        idx_to_song = {idx: song for song, idx in song_to_idx.items()}\n",
    "        \n",
    "        class SimplePreprocessor:\n",
    "            def __init__(self):\n",
    "                self.user_to_idx = user_to_idx\n",
    "                self.song_to_idx = song_to_idx\n",
    "                self.idx_to_user = idx_to_user\n",
    "                self.idx_to_song = idx_to_song\n",
    "        \n",
    "        preprocessor = SimplePreprocessor()\n",
    "        \n",
    "        # Construire matrice user-item\n",
    "        user_indices = triplets_df['user_id'].map(user_to_idx)\n",
    "        song_indices = triplets_df['song_id'].map(song_to_idx)\n",
    "        play_counts = triplets_df['play_count']\n",
    "        \n",
    "        user_item_matrix = csr_matrix(\n",
    "            (play_counts, (user_indices, song_indices)),\n",
    "            shape=(len(user_to_idx), len(song_to_idx))\n",
    "        )\n",
    "        \n",
    "        print(f\"Matrice construite: {user_item_matrix.shape}\")\n",
    "        print(f\"Sparsité: {1 - user_item_matrix.nnz / np.prod(user_item_matrix.shape):.4f}\")\n",
    "        \n",
    "        # Tester collaborative filtering\n",
    "        cf_recommender = UserBasedCF(user_item_matrix, preprocessor)\n",
    "        \n",
    "        # Test pour le premier utilisateur\n",
    "        user_idx = 0\n",
    "        user_id = idx_to_user[user_idx]\n",
    "        print(f\"\\nTest pour l'utilisateur: {user_id}\")\n",
    "        \n",
    "        # Voir ce que l'utilisateur a écouté\n",
    "        user_songs = user_item_matrix[user_idx].nonzero()[1]\n",
    "        print(f\"L'utilisateur a écouté {len(user_songs)} chansons différentes\")\n",
    "        \n",
    "        # Générer recommandations\n",
    "        recommendations = cf_recommender.recommend_for_user(user_idx, n_recommendations=5)\n",
    "        \n",
    "        if not recommendations.empty:\n",
    "            print(\"\\nRecommandations générées:\")\n",
    "            for _, rec in recommendations.iterrows():\n",
    "                song_id = rec['song_id']\n",
    "                # Essayer de trouver les infos du track\n",
    "                track_info = tracks_df[tracks_df['song_id'] == song_id]\n",
    "                if not track_info.empty:\n",
    "                    artist = track_info.iloc[0]['artist']\n",
    "                    title = track_info.iloc[0]['title']\n",
    "                    print(f\"{rec['rank']}. {artist} - {title} (score: {rec['score']:.3f})\")\n",
    "                else:\n",
    "                    print(f\"{rec['rank']}. {song_id} (score: {rec['score']:.3f})\")\n",
    "        else:\n",
    "            print(\"Aucune recommandation générée\")\n",
    "        \n",
    "        print(\"\\n✅ Test collaborative filtering terminé avec succès!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du test: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_collaborative_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a3f1e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 21:56:54,439 - INFO - === CHARGEMENT DE TOUTES LES DONNÉES ===\n",
      "2025-08-23 21:56:54,440 - INFO - Chargement des triplets...\n",
      "2025-08-23 21:57:12,455 - INFO - ✅ Triplets: 48373586 interactions\n",
      "2025-08-23 21:57:12,463 - INFO - Chargement des tracks...\n",
      "2025-08-23 21:57:23,155 - INFO - ✅ Tracks: 1000000 pistes\n",
      "2025-08-23 21:57:23,156 - INFO - Chargement des paroles...\n",
      "2025-08-23 21:57:27,033 - INFO - ✅ Paroles: 210519 pistes avec paroles\n",
      "2025-08-23 21:57:27,034 - INFO - Chargement des genres...\n",
      "2025-08-23 21:57:27,236 - INFO - ✅ Genres: 280831 pistes avec genres\n",
      "2025-08-23 21:57:27,237 - INFO - Création des mappings...\n",
      "2025-08-23 21:57:33,008 - INFO - ✅ Mappings: 1019318 users, 384546 songs\n",
      "2025-08-23 21:57:33,016 - INFO - Construction de la matrice user-item...\n",
      "2025-08-23 21:57:39,903 - INFO - ✅ Matrice: (1019318, 384546), sparsité: 0.999877\n",
      "2025-08-23 21:57:39,915 - INFO - \n",
      "🎵 GÉNÉRATION DE TOUTES LES RECOMMANDATIONS 🎵\n",
      "2025-08-23 21:57:39,915 - INFO - === 1. TOP-250 TRACKS ===\n",
      "2025-08-23 21:57:52,447 - INFO - ✅ Top-250 généré: 250 tracks\n",
      "2025-08-23 21:57:52,459 - INFO - === 2. TOP-100 PAR GENRE ===\n",
      "2025-08-23 21:57:52,540 - INFO - Génération top-100 Rock...\n",
      "2025-08-23 21:58:01,501 - INFO - ✅ Rock: 100 tracks\n",
      "2025-08-23 21:58:01,503 - INFO - Génération top-100 Rap...\n",
      "2025-08-23 21:58:07,676 - INFO - ✅ Rap: 100 tracks\n",
      "2025-08-23 21:58:07,679 - INFO - Génération top-100 Jazz...\n",
      "2025-08-23 21:58:13,725 - INFO - ✅ Jazz: 100 tracks\n",
      "2025-08-23 21:58:13,727 - INFO - Génération top-100 Electronic...\n",
      "2025-08-23 21:58:20,015 - INFO - ✅ Electronic: 100 tracks\n",
      "2025-08-23 21:58:20,017 - INFO - Génération top-100 Pop...\n",
      "2025-08-23 21:58:26,371 - INFO - ✅ Pop: 100 tracks\n",
      "2025-08-23 21:58:26,376 - INFO - Génération top-100 Blues...\n",
      "2025-08-23 21:58:32,283 - INFO - ✅ Blues: 100 tracks\n",
      "2025-08-23 21:58:32,286 - INFO - Génération top-100 Country...\n",
      "2025-08-23 21:58:38,907 - INFO - ✅ Country: 100 tracks\n",
      "2025-08-23 21:58:38,909 - INFO - Génération top-100 Reggae...\n",
      "2025-08-23 21:58:44,878 - INFO - ✅ Reggae: 100 tracks\n",
      "2025-08-23 21:58:44,964 - INFO - === COLLECTIONS THÉMATIQUES ===\n",
      "2025-08-23 21:58:44,965 - INFO - Génération collection 'love'...\n",
      "2025-08-23 21:58:49,933 - INFO - ✅ Collection 'love': 50 tracks\n",
      "2025-08-23 21:58:49,944 - INFO - Génération collection 'war'...\n",
      "2025-08-23 21:58:54,737 - INFO - ✅ Collection 'war': 50 tracks\n",
      "2025-08-23 21:58:54,743 - INFO - Génération collection 'happiness'...\n",
      "2025-08-23 21:58:59,969 - INFO - ✅ Collection 'happiness': 50 tracks\n",
      "2025-08-23 21:58:59,970 - INFO - === 4. USER-BASED COLLABORATIVE FILTERING ===\n",
      "2025-08-23 21:58:59,970 - INFO - Calcul pour les 100 premiers utilisateurs...\n",
      "2025-08-23 21:59:07,351 - INFO - ✅ Recommandations user-based: 190 recs pour 19 users\n",
      "2025-08-23 21:59:07,354 - INFO - === 5. ITEM-BASED COLLABORATIVE FILTERING ===\n",
      "2025-08-23 21:59:08,742 - INFO - ✅ Recommandations item-based: 32 recs\n",
      "2025-08-23 21:59:08,744 - INFO - === RÉSUMÉ FINAL ===\n",
      "2025-08-23 21:59:08,744 - INFO - ✅ Fichiers générés dans le dossier 'results/':\n",
      "2025-08-23 21:59:08,745 - INFO -    📄 top_100_pop.csv (6.0 KB)\n",
      "2025-08-23 21:59:08,745 - INFO -    📄 top_100_blues.csv (6.4 KB)\n",
      "2025-08-23 21:59:08,745 - INFO -    📄 top_100_country.csv (6.8 KB)\n",
      "2025-08-23 21:59:08,745 - INFO -    📄 top_100_rock.csv (6.1 KB)\n",
      "2025-08-23 21:59:08,746 - INFO -    📄 collection_war.csv (1.9 KB)\n",
      "2025-08-23 21:59:08,746 - INFO -    📄 top_250_tracks.csv (15.1 KB)\n",
      "2025-08-23 21:59:08,746 - INFO -    📄 top_100_electronic.csv (6.5 KB)\n",
      "2025-08-23 21:59:08,747 - INFO -    📄 top_100_jazz.csv (6.3 KB)\n",
      "2025-08-23 21:59:08,747 - INFO -    📄 top_100_reggae.csv (6.1 KB)\n",
      "2025-08-23 21:59:08,747 - INFO -    📄 collection_love.csv (2.1 KB)\n",
      "2025-08-23 21:59:08,747 - INFO -    📄 top_100_rap.csv (5.9 KB)\n",
      "2025-08-23 21:59:08,747 - INFO -    📄 user_based_recommendations.csv (20.7 KB)\n",
      "2025-08-23 21:59:08,748 - INFO -    📄 collection_happiness.csv (2.5 KB)\n",
      "2025-08-23 21:59:08,748 - INFO -    📄 item_based_recommendations.csv (2.8 KB)\n",
      "2025-08-23 21:59:08,748 - INFO - \n",
      "🎉 SYSTÈME MYSPOTIFY COMPLET EXÉCUTÉ AVEC SUCCÈS! 🎉\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🎵 MYSPOTIFY - SYSTÈME DE RECOMMANDATION MUSICAL 🎵\n",
      "==================================================\n",
      "✅ Top-250 tracks générés\n",
      "✅ 8 genres traités\n",
      "✅ 0 collections thématiques\n",
      "✅ Collaborative filtering utilisateur et item\n",
      "\n",
      "📁 Tous les résultats sont dans le dossier 'results/'\n"
     ]
    }
   ],
   "source": [
    "# complete_myspotify.py - Système complet de recommandations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Configuration du logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class MySpotifyComplete:\n",
    "    \"\"\"Système complet de recommandation musicale MySpotify\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=\".\"):\n",
    "        self.data_path = Path(data_path)\n",
    "        \n",
    "        # Données\n",
    "        self.triplets_df = None\n",
    "        self.tracks_df = None\n",
    "        self.lyrics_df = None\n",
    "        self.word_mapping = None\n",
    "        self.genre_df = None\n",
    "        \n",
    "        # Preprocessor\n",
    "        self.user_to_idx = {}\n",
    "        self.song_to_idx = {}\n",
    "        self.idx_to_user = {}\n",
    "        self.idx_to_song = {}\n",
    "        self.user_item_matrix = None\n",
    "        \n",
    "        # Résultats\n",
    "        self.results = {}\n",
    "    \n",
    "    def load_all_data(self):\n",
    "        \"\"\"Charge toutes les données nécessaires\"\"\"\n",
    "        logger.info(\"=== CHARGEMENT DE TOUTES LES DONNÉES ===\")\n",
    "        \n",
    "        # Triplets\n",
    "        logger.info(\"Chargement des triplets...\")\n",
    "        self.triplets_df = pd.read_csv(\n",
    "            self.data_path / \"train_triplets.txt\", \n",
    "            sep='\\t', names=['user_id', 'song_id', 'play_count']\n",
    "        )\n",
    "        logger.info(f\"✅ Triplets: {len(self.triplets_df)} interactions\")\n",
    "        \n",
    "        # Tracks\n",
    "        logger.info(\"Chargement des tracks...\")\n",
    "        self.tracks_df = pd.read_csv(\n",
    "            self.data_path / \"p02_unique_tracks.txt\", \n",
    "            sep='<SEP>', names=['track_id', 'song_id', 'artist', 'title'],\n",
    "            engine='python'\n",
    "        )\n",
    "        logger.info(f\"✅ Tracks: {len(self.tracks_df)} pistes\")\n",
    "        \n",
    "        # Paroles\n",
    "        logger.info(\"Chargement des paroles...\")\n",
    "        self.lyrics_df, self.word_mapping = self._load_lyrics()\n",
    "        logger.info(f\"✅ Paroles: {len(self.lyrics_df)} pistes avec paroles\")\n",
    "        \n",
    "        # Genres\n",
    "        logger.info(\"Chargement des genres...\")\n",
    "        self.genre_df = self._load_genres()\n",
    "        logger.info(f\"✅ Genres: {len(self.genre_df)} pistes avec genres\")\n",
    "        \n",
    "        # Preprocessing\n",
    "        self._create_mappings()\n",
    "        self._build_user_item_matrix()\n",
    "    \n",
    "    def _load_lyrics(self):\n",
    "        \"\"\"Charge les données de paroles\"\"\"\n",
    "        lyrics_data = []\n",
    "        word_mapping = {}\n",
    "        \n",
    "        with open(self.data_path / \"mxm_dataset_train.txt\", 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                \n",
    "                if line.startswith('#'):\n",
    "                    continue\n",
    "                \n",
    "                if line.startswith('%'):\n",
    "                    words = line[1:].split(',')\n",
    "                    word_mapping = {i+1: word for i, word in enumerate(words)}\n",
    "                    continue\n",
    "                \n",
    "                if line:\n",
    "                    parts = line.split(',')\n",
    "                    if len(parts) >= 2:\n",
    "                        track_id = parts[0]\n",
    "                        mxm_track_id = parts[1]\n",
    "                        \n",
    "                        word_counts = {}\n",
    "                        for part in parts[2:]:\n",
    "                            if ':' in part:\n",
    "                                try:\n",
    "                                    word_idx, count = part.split(':')\n",
    "                                    word_counts[int(word_idx)] = int(count)\n",
    "                                except ValueError:\n",
    "                                    continue\n",
    "                        \n",
    "                        lyrics_data.append({\n",
    "                            'track_id': track_id,\n",
    "                            'mxm_track_id': mxm_track_id,\n",
    "                            'word_counts': word_counts\n",
    "                        })\n",
    "        \n",
    "        return pd.DataFrame(lyrics_data), word_mapping\n",
    "    \n",
    "    def _load_genres(self):\n",
    "        \"\"\"Charge les données de genres\"\"\"\n",
    "        genres_data = []\n",
    "        with open(self.data_path / \"p02_msd_tagtraum_cd2.cls\", 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    parts = line.split('\\t')\n",
    "                    if len(parts) >= 2:\n",
    "                        track_id = parts[0]\n",
    "                        majority_genre = parts[1]\n",
    "                        minority_genre = parts[2] if len(parts) > 2 else None\n",
    "                        \n",
    "                        genres_data.append({\n",
    "                            'track_id': track_id,\n",
    "                            'majority_genre': majority_genre,\n",
    "                            'minority_genre': minority_genre\n",
    "                        })\n",
    "        \n",
    "        return pd.DataFrame(genres_data)\n",
    "    \n",
    "    def _create_mappings(self):\n",
    "        \"\"\"Crée les mappings bidirectionnels\"\"\"\n",
    "        logger.info(\"Création des mappings...\")\n",
    "        \n",
    "        unique_users = self.triplets_df['user_id'].unique()\n",
    "        unique_songs = self.triplets_df['song_id'].unique()\n",
    "        \n",
    "        self.user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.song_to_idx = {song: idx for idx, song in enumerate(unique_songs)}\n",
    "        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}\n",
    "        self.idx_to_song = {idx: song for song, idx in self.song_to_idx.items()}\n",
    "        \n",
    "        logger.info(f\"✅ Mappings: {len(self.user_to_idx)} users, {len(self.song_to_idx)} songs\")\n",
    "    \n",
    "    def _build_user_item_matrix(self):\n",
    "        \"\"\"Construit la matrice user-item\"\"\"\n",
    "        logger.info(\"Construction de la matrice user-item...\")\n",
    "        \n",
    "        user_indices = self.triplets_df['user_id'].map(self.user_to_idx)\n",
    "        song_indices = self.triplets_df['song_id'].map(self.song_to_idx)\n",
    "        play_counts = self.triplets_df['play_count']\n",
    "        \n",
    "        self.user_item_matrix = csr_matrix(\n",
    "            (play_counts, (user_indices, song_indices)),\n",
    "            shape=(len(self.user_to_idx), len(self.song_to_idx))\n",
    "        )\n",
    "        \n",
    "        sparsity = 1 - self.user_item_matrix.nnz / np.prod(self.user_item_matrix.shape)\n",
    "        logger.info(f\"✅ Matrice: {self.user_item_matrix.shape}, sparsité: {sparsity:.6f}\")\n",
    "    \n",
    "    def generate_top_250_tracks(self):\n",
    "        \"\"\"1. Top-250 tracks (Non-personnalisé)\"\"\"\n",
    "        logger.info(\"=== 1. TOP-250 TRACKS ===\")\n",
    "        \n",
    "        popularity = self.triplets_df.groupby('song_id')['play_count'].sum().sort_values(ascending=False)\n",
    "        top_songs = popularity.head(250)\n",
    "        \n",
    "        results = []\n",
    "        for i, (song_id, play_count) in enumerate(top_songs.items(), 1):\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            if not track_info.empty:\n",
    "                track_info = track_info.iloc[0]\n",
    "                results.append({\n",
    "                    'rank': i,\n",
    "                    'artist': track_info['artist'],\n",
    "                    'title': track_info['title'],\n",
    "                    'song_id': song_id,\n",
    "                    'play_count': int(play_count)\n",
    "                })\n",
    "        \n",
    "        df_result = pd.DataFrame(results)\n",
    "        df_result.to_csv('results/top_250_tracks.csv', index=False)\n",
    "        self.results['top_250'] = df_result\n",
    "        logger.info(f\"✅ Top-250 généré: {len(df_result)} tracks\")\n",
    "        return df_result\n",
    "    \n",
    "    def generate_top_by_genre(self):\n",
    "        \"\"\"2. Top-100 par genre (Non-personnalisé)\"\"\"\n",
    "        logger.info(\"=== 2. TOP-100 PAR GENRE ===\")\n",
    "        \n",
    "        available_genres = self.genre_df['majority_genre'].unique()\n",
    "        target_genres = ['Rock', 'Rap', 'Jazz', 'Electronic', 'Pop', 'Blues', 'Country', 'Reggae']\n",
    "        \n",
    "        all_genre_results = {}\n",
    "        \n",
    "        for genre in target_genres:\n",
    "            if genre in available_genres:\n",
    "                logger.info(f\"Génération top-100 {genre}...\")\n",
    "                \n",
    "                # Filtrer par genre\n",
    "                genre_tracks = self.genre_df[\n",
    "                    self.genre_df['majority_genre'] == genre\n",
    "                ]['track_id'].values\n",
    "                \n",
    "                genre_songs = self.tracks_df[\n",
    "                    self.tracks_df['track_id'].isin(genre_tracks)\n",
    "                ]['song_id'].values\n",
    "                \n",
    "                genre_triplets = self.triplets_df[\n",
    "                    self.triplets_df['song_id'].isin(genre_songs)\n",
    "                ]\n",
    "                \n",
    "                if not genre_triplets.empty:\n",
    "                    popularity = genre_triplets.groupby('song_id')['play_count'].sum().sort_values(ascending=False)\n",
    "                    top_songs = popularity.head(100)\n",
    "                    \n",
    "                    results = []\n",
    "                    for i, (song_id, play_count) in enumerate(top_songs.items(), 1):\n",
    "                        track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "                        if not track_info.empty:\n",
    "                            track_info = track_info.iloc[0]\n",
    "                            results.append({\n",
    "                                'rank': i,\n",
    "                                'genre': genre,\n",
    "                                'artist': track_info['artist'],\n",
    "                                'title': track_info['title'],\n",
    "                                'song_id': song_id,\n",
    "                                'play_count': int(play_count)\n",
    "                            })\n",
    "                    \n",
    "                    df_result = pd.DataFrame(results)\n",
    "                    df_result.to_csv(f'results/top_100_{genre.lower()}.csv', index=False)\n",
    "                    all_genre_results[genre] = df_result\n",
    "                    logger.info(f\"✅ {genre}: {len(df_result)} tracks\")\n",
    "        \n",
    "        self.results['genres'] = all_genre_results\n",
    "        return all_genre_results\n",
    "    \n",
    "    def generate_thematic_collections(self):\n",
    "        \"\"\"Collections thématiques - Version optimisée pour mémoire limitée\"\"\"\n",
    "        logger.info(\"=== COLLECTIONS THÉMATIQUES ===\")\n",
    "        \n",
    "        # 1. Configuration des thèmes (garder minimal)\n",
    "        themes = {\n",
    "            'love': ['love', 'heart'],  # Réduire le nombre de mots-clés\n",
    "            'war': ['war', 'fight'],\n",
    "            'happiness': ['happy', 'joy']\n",
    "        }\n",
    "        \n",
    "        # 2. Lecture du fichier par chunks pour économiser la mémoire\n",
    "        chunk_size = 10000  # Ajuster selon la RAM disponible\n",
    "        collections = {}\n",
    "        \n",
    "        for theme, keywords in themes.items():\n",
    "            logger.info(f\"Génération collection '{theme}'...\")\n",
    "            theme_scores = []\n",
    "            \n",
    "            # Créer index inversé pour les mots-clés\n",
    "            keyword_indices = set()\n",
    "            for keyword in keywords:\n",
    "                for idx, word in self.word_mapping.items():\n",
    "                    if keyword in word.lower():\n",
    "                        keyword_indices.add(idx)\n",
    "            \n",
    "            # Traiter les paroles par chunks\n",
    "            for chunk_start in range(0, len(self.lyrics_df), chunk_size):\n",
    "                chunk_end = min(chunk_start + chunk_size, len(self.lyrics_df))\n",
    "                chunk = self.lyrics_df.iloc[chunk_start:chunk_end]\n",
    "                \n",
    "                for _, row in chunk.iterrows():\n",
    "                    word_counts = row['word_counts']\n",
    "                    \n",
    "                    # Calcul score simplifié\n",
    "                    theme_score = sum(word_counts.get(idx, 0) for idx in keyword_indices)\n",
    "                    \n",
    "                    if theme_score > 0:\n",
    "                        theme_scores.append({\n",
    "                            'track_id': row['track_id'],\n",
    "                            'score': theme_score\n",
    "                        })\n",
    "                \n",
    "                # Libérer la mémoire\n",
    "                del chunk\n",
    "            \n",
    "            # Prendre uniquement les 50 meilleurs scores\n",
    "            theme_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "            top_50 = theme_scores[:50]\n",
    "            \n",
    "            # Formatage des résultats\n",
    "            results = []\n",
    "            for rank, item in enumerate(top_50, 1):\n",
    "                track_info = self.tracks_df[self.tracks_df['track_id'] == item['track_id']]\n",
    "                if not track_info.empty:\n",
    "                    track_info = track_info.iloc[0]\n",
    "                    results.append({\n",
    "                        'rank': rank,\n",
    "                        'theme': theme,\n",
    "                        'artist': track_info['artist'],\n",
    "                        'title': track_info['title'],\n",
    "                        'score': item['score']\n",
    "                    })\n",
    "            \n",
    "            if results:\n",
    "                df_result = pd.DataFrame(results)\n",
    "                df_result.to_csv(f'results/collection_{theme}.csv', index=False)\n",
    "                collections[theme] = df_result\n",
    "                logger.info(f\"✅ Collection '{theme}': {len(df_result)} tracks\")\n",
    "                \n",
    "            # Libérer la mémoire\n",
    "            del theme_scores\n",
    "        \n",
    "        return collections\n",
    "    \n",
    "    def generate_user_based_recommendations(self, n_users=100):\n",
    "        \"\"\"4. People similar to you listen (User-based CF)\"\"\"\n",
    "        logger.info(\"=== 4. USER-BASED COLLABORATIVE FILTERING ===\")\n",
    "        \n",
    "        # Utiliser un sous-ensemble d'utilisateurs pour éviter les problèmes mémoire\n",
    "        logger.info(f\"Calcul pour les {n_users} premiers utilisateurs...\")\n",
    "        \n",
    "        subset_matrix = self.user_item_matrix[:n_users, :]\n",
    "        normalized_matrix = normalize(subset_matrix, norm='l2', axis=1)\n",
    "        \n",
    "        # Calculer similarité\n",
    "        user_similarity = cosine_similarity(normalized_matrix)\n",
    "        \n",
    "        user_recommendations = []\n",
    "        \n",
    "        for user_idx in range(min(20, n_users)):  # Test sur 20 premiers utilisateurs\n",
    "            user_id = self.idx_to_user[user_idx]\n",
    "            \n",
    "            # Trouver utilisateurs similaires\n",
    "            similarities = user_similarity[user_idx]\n",
    "            similarities[user_idx] = -1  # Exclure l'utilisateur lui-même\n",
    "            \n",
    "            similar_users = np.argsort(similarities)[::-1][:20]  # Top 20 similaires\n",
    "            \n",
    "            # Générer recommandations\n",
    "            user_items = subset_matrix[user_idx].toarray()[0]\n",
    "            recommendations = np.zeros(subset_matrix.shape[1])\n",
    "            \n",
    "            for similar_user_idx in similar_users:\n",
    "                if similarities[similar_user_idx] > 0:\n",
    "                    sim_score = similarities[similar_user_idx]\n",
    "                    similar_items = subset_matrix[similar_user_idx].toarray()[0]\n",
    "                    \n",
    "                    unseen_items = (user_items == 0) & (similar_items > 0)\n",
    "                    recommendations[unseen_items] += sim_score * similar_items[unseen_items]\n",
    "            \n",
    "            # Sélectionner top 10\n",
    "            if recommendations.sum() > 0:\n",
    "                top_items = np.argsort(recommendations)[::-1][:10]\n",
    "                \n",
    "                for rank, item_idx in enumerate(top_items, 1):\n",
    "                    if recommendations[item_idx] > 0:\n",
    "                        song_id = self.idx_to_song.get(item_idx, 'Unknown')\n",
    "                        track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "                        \n",
    "                        if not track_info.empty:\n",
    "                            track_info = track_info.iloc[0]\n",
    "                            user_recommendations.append({\n",
    "                                'user_id': user_id,\n",
    "                                'rank': rank,\n",
    "                                'artist': track_info['artist'],\n",
    "                                'title': track_info['title'],\n",
    "                                'song_id': song_id,\n",
    "                                'score': float(recommendations[item_idx])\n",
    "                            })\n",
    "        \n",
    "        if user_recommendations:\n",
    "            df_result = pd.DataFrame(user_recommendations)\n",
    "            df_result.to_csv('results/user_based_recommendations.csv', index=False)\n",
    "            self.results['user_cf'] = df_result\n",
    "            logger.info(f\"✅ Recommandations user-based: {len(df_result)} recs pour {df_result['user_id'].nunique()} users\")\n",
    "        \n",
    "        return user_recommendations\n",
    "    \n",
    "    def generate_item_based_recommendations(self, n_items=100):\n",
    "        \"\"\"5. People who listen to this track usually listen (Item-based CF)\"\"\"\n",
    "        logger.info(\"=== 5. ITEM-BASED COLLABORATIVE FILTERING ===\")\n",
    "        \n",
    "        # Utiliser un sous-ensemble d'items\n",
    "        subset_matrix = self.user_item_matrix[:, :n_items]\n",
    "        \n",
    "        # Transposer pour avoir items x users\n",
    "        item_user_matrix = subset_matrix.T\n",
    "        normalized_matrix = normalize(item_user_matrix, norm='l2', axis=1)\n",
    "        \n",
    "        # Calculer similarité entre items\n",
    "        item_similarity = cosine_similarity(normalized_matrix)\n",
    "        \n",
    "        item_recommendations = []\n",
    "        \n",
    "        # Test sur quelques items populaires\n",
    "        popular_items = np.array(subset_matrix.sum(axis=0)).flatten()\n",
    "        top_items_idx = np.argsort(popular_items)[::-1][:20]  # 20 items les plus populaires\n",
    "        \n",
    "        for item_idx in top_items_idx:\n",
    "            if item_idx < item_similarity.shape[0]:\n",
    "                song_id = self.idx_to_song.get(item_idx, 'Unknown')\n",
    "                \n",
    "                # Trouver items similaires\n",
    "                similarities = item_similarity[item_idx]\n",
    "                similarities[item_idx] = -1  # Exclure l'item lui-même\n",
    "                \n",
    "                similar_items = np.argsort(similarities)[::-1][:10]\n",
    "                \n",
    "                for rank, similar_idx in enumerate(similar_items, 1):\n",
    "                    if similarities[similar_idx] > 0.1:  # Seuil de similarité\n",
    "                        similar_song_id = self.idx_to_song.get(similar_idx, 'Unknown')\n",
    "                        track_info = self.tracks_df[self.tracks_df['song_id'] == similar_song_id]\n",
    "                        \n",
    "                        if not track_info.empty:\n",
    "                            track_info = track_info.iloc[0]\n",
    "                            item_recommendations.append({\n",
    "                                'seed_song_id': song_id,\n",
    "                                'rank': rank,\n",
    "                                'artist': track_info['artist'],\n",
    "                                'title': track_info['title'],\n",
    "                                'recommended_song_id': similar_song_id,\n",
    "                                'similarity': float(similarities[similar_idx])\n",
    "                            })\n",
    "        \n",
    "        if item_recommendations:\n",
    "            df_result = pd.DataFrame(item_recommendations)\n",
    "            df_result.to_csv('results/item_based_recommendations.csv', index=False)\n",
    "            self.results['item_cf'] = df_result\n",
    "            logger.info(f\"✅ Recommandations item-based: {len(df_result)} recs\")\n",
    "        \n",
    "        return item_recommendations\n",
    "    \n",
    "    def run_complete_system(self):\n",
    "        \"\"\"Exécute le système complet de recommandations\"\"\"\n",
    "        \n",
    "        # Créer dossier results\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "        \n",
    "        # Charger toutes les données\n",
    "        self.load_all_data()\n",
    "        \n",
    "        # Générer toutes les recommandations\n",
    "        logger.info(\"\\n🎵 GÉNÉRATION DE TOUTES LES RECOMMANDATIONS 🎵\")\n",
    "        \n",
    "        self.generate_top_250_tracks()\n",
    "        self.generate_top_by_genre()\n",
    "        self.generate_thematic_collections()\n",
    "        self.generate_user_based_recommendations()\n",
    "        self.generate_item_based_recommendations()\n",
    "        \n",
    "        # Résumé final\n",
    "        logger.info(\"=== RÉSUMÉ FINAL ===\")\n",
    "        logger.info(\"✅ Fichiers générés dans le dossier 'results/':\")\n",
    "        \n",
    "        for file in Path('results').glob('*.csv'):\n",
    "            size_kb = file.stat().st_size / 1024\n",
    "            logger.info(f\"   📄 {file.name} ({size_kb:.1f} KB)\")\n",
    "        \n",
    "        logger.info(\"\\n🎉 SYSTÈME MYSPOTIFY COMPLET EXÉCUTÉ AVEC SUCCÈS! 🎉\")\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale\"\"\"\n",
    "    try:\n",
    "        myspotify = MySpotifyComplete()\n",
    "        results = myspotify.run_complete_system()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"🎵 MYSPOTIFY - SYSTÈME DE RECOMMANDATION MUSICAL 🎵\")\n",
    "        print(\"=\"*50)\n",
    "        print(f\"✅ Top-250 tracks générés\")\n",
    "        print(f\"✅ {len(results.get('genres', {}))} genres traités\")\n",
    "        print(f\"✅ {len(results.get('collections', {}))} collections thématiques\")\n",
    "        print(f\"✅ Collaborative filtering utilisateur et item\")\n",
    "        print(\"\\n📁 Tous les résultats sont dans le dossier 'results/'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Erreur lors de l'exécution: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10730b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🎵 ANALYSE DES RÉSULTATS MYSPOTIFY 🎵\n",
      "============================================================\n",
      "📁 Fichiers trouvés: 14\n",
      "\n",
      "📄 collection_happiness.csv\n",
      "   • Taille: 2.5 KB\n",
      "   • Lignes: 50\n",
      "   • Colonnes: ['rank', 'theme', 'artist', 'title', 'score']\n",
      "   • Exemple: The Sundays - Joy\n",
      "\n",
      "📄 collection_love.csv\n",
      "   • Taille: 2.1 KB\n",
      "   • Lignes: 50\n",
      "   • Colonnes: ['rank', 'theme', 'artist', 'title', 'score']\n",
      "   • Exemple: Jessica Simpson - I Think I'm In Love With You\n",
      "\n",
      "📄 collection_war.csv\n",
      "   • Taille: 1.9 KB\n",
      "   • Lignes: 50\n",
      "   • Colonnes: ['rank', 'theme', 'artist', 'title', 'score']\n",
      "   • Exemple: Culture Club - The War Song (2003 Digital Remaster)\n",
      "\n",
      "📄 item_based_recommendations.csv\n",
      "   • Taille: 2.8 KB\n",
      "   • Lignes: 32\n",
      "   • Colonnes: ['seed_song_id', 'rank', 'artist', 'title', 'recommended_song_id', 'similarity']\n",
      "   • Exemple: The String Cheese Incident - Bigger Isn't Better\n",
      "\n",
      "📄 top_100_blues.csv\n",
      "   • Taille: 6.4 KB\n",
      "   • Lignes: 100\n",
      "   • Colonnes: ['rank', 'genre', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Sonny Boy Williamson - Don't Start Me Talkin'\n",
      "\n",
      "📄 top_100_country.csv\n",
      "   • Taille: 6.8 KB\n",
      "   • Lignes: 100\n",
      "   • Colonnes: ['rank', 'genre', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Dwight Yoakam - You're The One\n",
      "\n",
      "📄 top_100_electronic.csv\n",
      "   • Taille: 6.5 KB\n",
      "   • Lignes: 100\n",
      "   • Colonnes: ['rank', 'genre', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Southside Spinners - Luvstruck\n",
      "\n",
      "📄 top_100_jazz.csv\n",
      "   • Taille: 6.3 KB\n",
      "   • Lignes: 100\n",
      "   • Colonnes: ['rank', 'genre', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Ron Carter - I CAN'T GET STARTED\n",
      "\n",
      "📄 top_100_pop.csv\n",
      "   • Taille: 6.0 KB\n",
      "   • Lignes: 100\n",
      "   • Colonnes: ['rank', 'genre', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Train - Marry Me\n",
      "\n",
      "📄 top_100_rap.csv\n",
      "   • Taille: 5.9 KB\n",
      "   • Lignes: 100\n",
      "   • Colonnes: ['rank', 'genre', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Alliance Ethnik - Représente\n",
      "\n",
      "📄 top_100_reggae.csv\n",
      "   • Taille: 6.1 KB\n",
      "   • Lignes: 100\n",
      "   • Colonnes: ['rank', 'genre', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Eddy Grant - Electric Avenue\n",
      "\n",
      "📄 top_100_rock.csv\n",
      "   • Taille: 6.1 KB\n",
      "   • Lignes: 100\n",
      "   • Colonnes: ['rank', 'genre', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Björk - Undo\n",
      "\n",
      "📄 top_250_tracks.csv\n",
      "   • Taille: 15.1 KB\n",
      "   • Lignes: 250\n",
      "   • Colonnes: ['rank', 'artist', 'title', 'song_id', 'play_count']\n",
      "   • Exemple: Dwight Yoakam - You're The One\n",
      "\n",
      "📄 user_based_recommendations.csv\n",
      "   • Taille: 20.7 KB\n",
      "   • Lignes: 190\n",
      "   • Colonnes: ['user_id', 'rank', 'artist', 'title', 'song_id', 'score']\n",
      "   • Exemple: Björk - Undo\n",
      "\n",
      "============================================================\n",
      "📊 RÉSUMÉ FINAL\n",
      "============================================================\n",
      "🎯 Total des recommandations: 1,422\n",
      "📋 Composants implémentés: 14\n",
      "\n",
      "🎵 Composants trouvés:\n",
      "   ✅ Collection Happiness\n",
      "   ✅ Collection Love\n",
      "   ✅ Collection War\n",
      "   ✅ Item-based Collaborative Filtering\n",
      "   ✅ Top-100 Blues\n",
      "   ✅ Top-100 Country\n",
      "   ✅ Top-100 Electronic\n",
      "   ✅ Top-100 Jazz\n",
      "   ✅ Top-100 Pop\n",
      "   ✅ Top-100 Rap\n",
      "   ✅ Top-100 Reggae\n",
      "   ✅ Top-100 Rock\n",
      "   ✅ Top-250 tracks\n",
      "   ✅ User-based Collaborative Filtering\n",
      "\n",
      "📋 VÉRIFICATION EXIGENCES PROJET:\n",
      "   ✅ Top-250 tracks\n",
      "   ✅ User-based CF\n",
      "   ✅ Item-based CF\n",
      "   ✅ Recommandations par genre (8 genres)\n",
      "   ✅ Collections thématiques (3 thèmes)\n",
      "\n",
      "🎉 FÉLICITATIONS! Tous les composants requis sont présents!\n",
      "✅ Votre projet MySpotify est COMPLET!\n",
      "============================================================\n",
      "\n",
      "🎵 ÉCHANTILLONS DE RECOMMANDATIONS\n",
      "==================================================\n",
      "\n",
      "🏆 TOP 5 TRACKS LES PLUS POPULAIRES:\n",
      "----------------------------------------\n",
      " 1. Dwight Yoakam - You're The One\n",
      "    Play count: 726,885\n",
      " 2. Björk - Undo\n",
      "    Play count: 648,239\n",
      " 3. Kings Of Leon - Revelry\n",
      "    Play count: 527,893\n",
      " 4. Harmonia - Sehr kosmisch\n",
      "    Play count: 425,463\n",
      " 5. Barry Tuckwell/Academy of St Martin-in-the-Fields/Sir Neville Marriner - Horn Concerto No. 4 in E flat K495: II. Romance (Andante cantabile)\n",
      "    Play count: 389,880\n",
      "\n",
      "💖 TOP 5 CHANSONS D'AMOUR:\n",
      "----------------------------------------\n",
      " 1. Jessica Simpson - I Think I'm In Love With You\n",
      " 2. Jessica Simpson - Betcha She Don't Love You\n",
      " 3. Jill Scott - It's Love\n",
      " 4. Shaggy - All About Love\n",
      " 5. Bill Withers - Lovely Day\n",
      "\n",
      "🎸 TOP 5 ROCK:\n",
      "----------------------------------------\n",
      " 1. Björk - Undo\n",
      "    Play count: 648,239\n",
      " 2. Kings Of Leon - Revelry\n",
      "    Play count: 527,893\n",
      " 3. Harmonia - Sehr kosmisch\n",
      "    Play count: 425,463\n",
      " 4. OneRepublic - Secrets\n",
      "    Play count: 292,642\n",
      " 5. Tub Ring - Invalid\n",
      "    Play count: 268,353\n",
      "\n",
      "📁 Pour voir tous les détails, consultez le dossier 'results/'\n"
     ]
    }
   ],
   "source": [
    "# simple_analyzer.py - Version simplifiée de l'analyseur MySpotify\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def analyze_myspotify_results():\n",
    "    \"\"\"Analyse simple des résultats MySpotify\"\"\"\n",
    "    \n",
    "    results_path = Path(\"results\")\n",
    "    \n",
    "    if not results_path.exists():\n",
    "        print(\"❌ Dossier 'results' non trouvé.\")\n",
    "        print(\"   Exécutez d'abord: python complete_myspotify.py\")\n",
    "        return\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"🎵 ANALYSE DES RÉSULTATS MYSPOTIFY 🎵\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Lister tous les fichiers CSV\n",
    "    csv_files = list(results_path.glob(\"*.csv\"))\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"❌ Aucun fichier CSV trouvé dans le dossier results/\")\n",
    "        return\n",
    "    \n",
    "    print(f\"📁 Fichiers trouvés: {len(csv_files)}\")\n",
    "    print()\n",
    "    \n",
    "    total_recommendations = 0\n",
    "    components_found = []\n",
    "    \n",
    "    # Analyser chaque fichier\n",
    "    for file in sorted(csv_files):\n",
    "        try:\n",
    "            df = pd.read_csv(file)\n",
    "            file_size_kb = file.stat().st_size / 1024\n",
    "            \n",
    "            print(f\"📄 {file.name}\")\n",
    "            print(f\"   • Taille: {file_size_kb:.1f} KB\")\n",
    "            print(f\"   • Lignes: {len(df)}\")\n",
    "            print(f\"   • Colonnes: {list(df.columns)}\")\n",
    "            \n",
    "            # Échantillon des données\n",
    "            if len(df) > 0:\n",
    "                if 'artist' in df.columns and 'title' in df.columns:\n",
    "                    print(f\"   • Exemple: {df.iloc[0]['artist']} - {df.iloc[0]['title']}\")\n",
    "                total_recommendations += len(df)\n",
    "            \n",
    "            # Identifier le type de composant\n",
    "            if file.name == \"top_250_tracks.csv\":\n",
    "                components_found.append(\"✅ Top-250 tracks\")\n",
    "            elif file.name.startswith(\"top_100_\"):\n",
    "                genre = file.name.replace(\"top_100_\", \"\").replace(\".csv\", \"\").title()\n",
    "                components_found.append(f\"✅ Top-100 {genre}\")\n",
    "            elif file.name.startswith(\"collection_\"):\n",
    "                theme = file.name.replace(\"collection_\", \"\").replace(\".csv\", \"\").title()\n",
    "                components_found.append(f\"✅ Collection {theme}\")\n",
    "            elif file.name == \"user_based_recommendations.csv\":\n",
    "                components_found.append(\"✅ User-based Collaborative Filtering\")\n",
    "            elif file.name == \"item_based_recommendations.csv\":\n",
    "                components_found.append(\"✅ Item-based Collaborative Filtering\")\n",
    "            \n",
    "            print()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erreur lecture {file.name}: {e}\")\n",
    "            print()\n",
    "    \n",
    "    # Résumé final\n",
    "    print(\"=\"*60)\n",
    "    print(\"📊 RÉSUMÉ FINAL\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"🎯 Total des recommandations: {total_recommendations:,}\")\n",
    "    print(f\"📋 Composants implémentés: {len(components_found)}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"🎵 Composants trouvés:\")\n",
    "    for component in components_found:\n",
    "        print(f\"   {component}\")\n",
    "    \n",
    "    # Vérification des exigences projet\n",
    "    print()\n",
    "    print(\"📋 VÉRIFICATION EXIGENCES PROJET:\")\n",
    "    \n",
    "    required_files = {\n",
    "        \"top_250_tracks.csv\": \"Top-250 tracks\",\n",
    "        \"user_based_recommendations.csv\": \"User-based CF\", \n",
    "        \"item_based_recommendations.csv\": \"Item-based CF\"\n",
    "    }\n",
    "    \n",
    "    genre_files = [f for f in csv_files if f.name.startswith(\"top_100_\")]\n",
    "    collection_files = [f for f in csv_files if f.name.startswith(\"collection_\")]\n",
    "    \n",
    "    # Vérifications\n",
    "    all_good = True\n",
    "    \n",
    "    for req_file, description in required_files.items():\n",
    "        if any(f.name == req_file for f in csv_files):\n",
    "            print(f\"   ✅ {description}\")\n",
    "        else:\n",
    "            print(f\"   ❌ {description} - MANQUANT\")\n",
    "            all_good = False\n",
    "    \n",
    "    if len(genre_files) > 0:\n",
    "        print(f\"   ✅ Recommandations par genre ({len(genre_files)} genres)\")\n",
    "    else:\n",
    "        print(f\"   ❌ Recommandations par genre - MANQUANT\")\n",
    "        all_good = False\n",
    "    \n",
    "    if len(collection_files) > 0:\n",
    "        print(f\"   ✅ Collections thématiques ({len(collection_files)} thèmes)\")\n",
    "    else:\n",
    "        print(f\"   ❌ Collections thématiques - MANQUANT\")\n",
    "        all_good = False\n",
    "    \n",
    "    print()\n",
    "    if all_good:\n",
    "        print(\"🎉 FÉLICITATIONS! Tous les composants requis sont présents!\")\n",
    "        print(\"✅ Votre projet MySpotify est COMPLET!\")\n",
    "    else:\n",
    "        print(\"⚠️  Certains composants manquent.\")\n",
    "        print(\"   Exécutez: python complete_myspotify.py\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "def show_sample_recommendations():\n",
    "    \"\"\"Affiche des échantillons de recommandations\"\"\"\n",
    "    \n",
    "    print(\"\\n🎵 ÉCHANTILLONS DE RECOMMANDATIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    results_path = Path(\"results\")\n",
    "    \n",
    "    # Top-250\n",
    "    top_250_file = results_path / \"top_250_tracks.csv\"\n",
    "    if top_250_file.exists():\n",
    "        df = pd.read_csv(top_250_file)\n",
    "        print(\"\\n🏆 TOP 5 TRACKS LES PLUS POPULAIRES:\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, row in df.head(5).iterrows():\n",
    "            print(f\"{row['rank']:2d}. {row['artist']} - {row['title']}\")\n",
    "            print(f\"    Play count: {row['play_count']:,}\")\n",
    "    \n",
    "    # Collection amour\n",
    "    love_file = results_path / \"collection_love.csv\"\n",
    "    if love_file.exists():\n",
    "        df = pd.read_csv(love_file)\n",
    "        print(f\"\\n💖 TOP 5 CHANSONS D'AMOUR:\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, row in df.head(5).iterrows():\n",
    "            print(f\"{row['rank']:2d}. {row['artist']} - {row['title']}\")\n",
    "            if 'theme_score' in row:\n",
    "                print(f\"    Score thématique: {row['theme_score']}\")\n",
    "    \n",
    "    # Rock\n",
    "    rock_file = results_path / \"top_100_rock.csv\"\n",
    "    if rock_file.exists():\n",
    "        df = pd.read_csv(rock_file)\n",
    "        print(f\"\\n🎸 TOP 5 ROCK:\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, row in df.head(5).iterrows():\n",
    "            print(f\"{row['rank']:2d}. {row['artist']} - {row['title']}\")\n",
    "            print(f\"    Play count: {row['play_count']:,}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Fonction principale\"\"\"\n",
    "    try:\n",
    "        analyze_myspotify_results()\n",
    "        show_sample_recommendations()\n",
    "        \n",
    "        print(f\"\\n📁 Pour voir tous les détails, consultez le dossier 'results/'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "636dc409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-24 01:48:41,365 - INFO - Chargement des données de base...\n",
      "2025-08-24 01:49:11,006 - INFO - ✅ Données de base chargées\n",
      "2025-08-24 01:49:11,014 - INFO - \n",
      "🎵 EXÉCUTION DES FONCTIONNALITÉS BONUS 🎵\n",
      "2025-08-24 01:49:11,015 - INFO - Inspirées de Spotify, Apple Music, etc.\n",
      "2025-08-24 01:49:11,015 - INFO - === BONUS 1: DISCOVER WEEKLY ===\n",
      "2025-08-24 01:49:11,026 - INFO - Génération Discover Weekly pour 9bd1a6b1d802d781b494172bdeffba7f32883e53...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "🔍 1. Discover Weekly...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 670\u001b[0m\n\u001b[1;32m    667\u001b[0m         traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 670\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 609\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;66;03m# BONUS 1: Discover Weekly\u001b[39;00m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m🔍 1. Discover Weekly...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 609\u001b[0m discover_weekly \u001b[38;5;241m=\u001b[39m \u001b[43mspotify_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscover_weekly\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m discover_weekly\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Discover Weekly généré: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(discover_weekly)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tracks\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 108\u001b[0m, in \u001b[0;36mSpotifyInspiredFeatures.discover_weekly\u001b[0;34m(self, user_id, n_tracks)\u001b[0m\n\u001b[1;32m    105\u001b[0m recommendations\u001b[38;5;241m.\u001b[39mextend(genre_recs)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# 30% - Découverte pure (tendances récentes, diversité)\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m discovery_recs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_pure_discovery\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_tracks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m recommendations\u001b[38;5;241m.\u001b[39mextend(discovery_recs)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# 3. Diversification et déduplication\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 346\u001b[0m, in \u001b[0;36mSpotifyInspiredFeatures._get_pure_discovery\u001b[0;34m(self, user_id, n_tracks)\u001b[0m\n\u001b[1;32m    344\u001b[0m best_popularity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m song_id \u001b[38;5;129;01min\u001b[39;00m unheard_songs:\n\u001b[0;32m--> 346\u001b[0m     pop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtriplets_df[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtriplets_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msong_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msong_id\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplay_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pop \u001b[38;5;241m>\u001b[39m best_popularity:\n\u001b[1;32m    348\u001b[0m         best_popularity \u001b[38;5;241m=\u001b[39m pop\n",
      "File \u001b[0;32m~/miniforge3/envs/IA_projects/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/IA_projects/lib/python3.10/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/IA_projects/lib/python3.10/site-packages/pandas/core/series.py:6130\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6127\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6128\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6130\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniforge3/envs/IA_projects/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/IA_projects/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# myspotify_bonus.py - Fonctionnalités bonus inspirées des services de streaming\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SpotifyInspiredFeatures:\n",
    "    \"\"\"Fonctionnalités bonus inspirées de Spotify, Apple Music, etc.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path=\".\"):\n",
    "        self.data_path = Path(data_path)\n",
    "        self.load_base_data()\n",
    "    \n",
    "    def load_base_data(self):\n",
    "        \"\"\"Charge les données de base\"\"\"\n",
    "        logger.info(\"Chargement des données de base...\")\n",
    "        \n",
    "        # Charger données existantes\n",
    "        self.triplets_df = pd.read_csv(\n",
    "            self.data_path / \"train_triplets.txt\",\n",
    "            sep='\\t', names=['user_id', 'song_id', 'play_count']\n",
    "        )\n",
    "        \n",
    "        self.tracks_df = pd.read_csv(\n",
    "            self.data_path / \"p02_unique_tracks.txt\",\n",
    "            sep='<SEP>', names=['track_id', 'song_id', 'artist', 'title'],\n",
    "            engine='python'\n",
    "        )\n",
    "        \n",
    "        # Charger genres\n",
    "        self.genre_df = self._load_genres()\n",
    "        \n",
    "        # Créer mappings\n",
    "        self._create_mappings()\n",
    "        \n",
    "        logger.info(\"✅ Données de base chargées\")\n",
    "    \n",
    "    def _load_genres(self):\n",
    "        \"\"\"Charge les genres\"\"\"\n",
    "        genres_data = []\n",
    "        try:\n",
    "            with open(self.data_path / \"p02_msd_tagtraum_cd2.cls\", 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line and not line.startswith('#'):\n",
    "                        parts = line.split('\\t')\n",
    "                        if len(parts) >= 2:\n",
    "                            genres_data.append({\n",
    "                                'track_id': parts[0],\n",
    "                                'majority_genre': parts[1],\n",
    "                                'minority_genre': parts[2] if len(parts) > 2 else None\n",
    "                            })\n",
    "        except:\n",
    "            logger.warning(\"Impossible de charger les genres\")\n",
    "        \n",
    "        return pd.DataFrame(genres_data)\n",
    "    \n",
    "    def _create_mappings(self):\n",
    "        \"\"\"Crée les mappings\"\"\"\n",
    "        unique_users = self.triplets_df['user_id'].unique()\n",
    "        unique_songs = self.triplets_df['song_id'].unique()\n",
    "        \n",
    "        self.user_to_idx = {user: idx for idx, user in enumerate(unique_users)}\n",
    "        self.song_to_idx = {song: idx for idx, song in enumerate(unique_songs)}\n",
    "        self.idx_to_user = {idx: user for user, idx in self.user_to_idx.items()}\n",
    "        self.idx_to_song = {idx: song for song, idx in self.song_to_idx.items()}\n",
    "    \n",
    "    def discover_weekly(self, user_id=None, n_tracks=30):\n",
    "        \"\"\"\n",
    "        BONUS 1: \"Discover Weekly\" - Playlist de découverte personnalisée\n",
    "        Inspiré de la fonctionnalité Spotify Discover Weekly\n",
    "        \"\"\"\n",
    "        logger.info(\"=== BONUS 1: DISCOVER WEEKLY ===\")\n",
    "        \n",
    "        if user_id is None:\n",
    "            # Prendre un utilisateur au hasard\n",
    "            user_id = random.choice(list(self.user_to_idx.keys()))\n",
    "        \n",
    "        if user_id not in self.user_to_idx:\n",
    "            logger.warning(f\"Utilisateur {user_id} non trouvé\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        logger.info(f\"Génération Discover Weekly pour {user_id}...\")\n",
    "        \n",
    "        # 1. Analyser le profil de l'utilisateur\n",
    "        user_profile = self._analyze_user_profile(user_id)\n",
    "        \n",
    "        # 2. Recommandations hybrides\n",
    "        recommendations = []\n",
    "        \n",
    "        # 40% - Collaborative Filtering (artistes similaires non écoutés)\n",
    "        cf_recs = self._get_cf_discoveries(user_id, int(n_tracks * 0.4))\n",
    "        recommendations.extend(cf_recs)\n",
    "        \n",
    "        # 30% - Expansion par genre (genres aimés, artistes non écoutés)\n",
    "        genre_recs = self._get_genre_expansion(user_id, user_profile, int(n_tracks * 0.3))\n",
    "        recommendations.extend(genre_recs)\n",
    "        \n",
    "        # 30% - Découverte pure (tendances récentes, diversité)\n",
    "        discovery_recs = self._get_pure_discovery(user_id, int(n_tracks * 0.3))\n",
    "        recommendations.extend(discovery_recs)\n",
    "        \n",
    "        # 3. Diversification et déduplication\n",
    "        final_playlist = self._diversify_playlist(recommendations, n_tracks)\n",
    "        \n",
    "        # 4. Formatage final\n",
    "        playlist = []\n",
    "        for i, (song_id, score, reason) in enumerate(final_playlist, 1):\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            if not track_info.empty:\n",
    "                track_info = track_info.iloc[0]\n",
    "                playlist.append({\n",
    "                    'rank': i,\n",
    "                    'artist': track_info['artist'],\n",
    "                    'title': track_info['title'],\n",
    "                    'song_id': song_id,\n",
    "                    'discovery_score': float(score),\n",
    "                    'reason': reason\n",
    "                })\n",
    "        \n",
    "        df_result = pd.DataFrame(playlist)\n",
    "        df_result.to_csv(f'results/bonus_discover_weekly_{user_id[:8]}.csv', index=False)\n",
    "        \n",
    "        logger.info(f\"✅ Discover Weekly généré: {len(df_result)} tracks\")\n",
    "        return df_result\n",
    "    \n",
    "    def artist_radio(self, seed_artist, n_tracks=50):\n",
    "        \"\"\"\n",
    "        BONUS 2: \"Artist Radio\" - Radio basée sur un artiste\n",
    "        Inspiré des radios Spotify/Apple Music\n",
    "        \"\"\"\n",
    "        logger.info(\"=== BONUS 2: ARTIST RADIO ===\")\n",
    "        logger.info(f\"Création radio pour l'artiste: {seed_artist}\")\n",
    "        \n",
    "        # 1. Vérifier que l'artiste existe\n",
    "        artist_songs = self.tracks_df[self.tracks_df['artist'] == seed_artist]\n",
    "        if artist_songs.empty:\n",
    "            logger.warning(f\"Artiste '{seed_artist}' non trouvé\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # 2. Analyser le profil de l'artiste\n",
    "        artist_profile = self._analyze_artist_profile(seed_artist)\n",
    "        \n",
    "        # 3. Construire la radio par expansion\n",
    "        radio_tracks = []\n",
    "        \n",
    "        # 20% - Tracks de l'artiste original (hits principaux)\n",
    "        original_tracks = self._get_artist_hits(seed_artist, int(n_tracks * 0.2))\n",
    "        radio_tracks.extend([(song_id, score, \"Original Artist\") for song_id, score in original_tracks])\n",
    "        \n",
    "        # 40% - Artistes similaires par genre\n",
    "        genre_similar = self._get_genre_similar_artists(seed_artist, artist_profile, int(n_tracks * 0.4))\n",
    "        radio_tracks.extend([(song_id, score, \"Similar Genre\") for song_id, score in genre_similar])\n",
    "        \n",
    "        # 30% - Artistes co-écoutés (collaborative)\n",
    "        collab_similar = self._get_collaborative_similar_artists(seed_artist, int(n_tracks * 0.3))\n",
    "        radio_tracks.extend([(song_id, score, \"Fans Also Like\") for song_id, score in collab_similar])\n",
    "        \n",
    "        # 10% - Découverte (nouveaux artistes du même genre)\n",
    "        discovery = self._get_radio_discovery(artist_profile, int(n_tracks * 0.1))\n",
    "        radio_tracks.extend([(song_id, score, \"Discovery\") for song_id, score in discovery])\n",
    "        \n",
    "        # 4. Créer un flow naturel (variation d'énergie)\n",
    "        final_radio = self._create_radio_flow(radio_tracks, n_tracks)\n",
    "        \n",
    "        # 5. Formatage\n",
    "        radio = []\n",
    "        for i, (song_id, score, reason) in enumerate(final_radio, 1):\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            if not track_info.empty:\n",
    "                track_info = track_info.iloc[0]\n",
    "                radio.append({\n",
    "                    'position': i,\n",
    "                    'artist': track_info['artist'],\n",
    "                    'title': track_info['title'],\n",
    "                    'song_id': song_id,\n",
    "                    'radio_score': float(score),\n",
    "                    'category': reason\n",
    "                })\n",
    "        \n",
    "        df_result = pd.DataFrame(radio)\n",
    "        safe_artist = seed_artist.replace('/', '_').replace(' ', '_')[:20]\n",
    "        df_result.to_csv(f'results/bonus_artist_radio_{safe_artist}.csv', index=False)\n",
    "        \n",
    "        logger.info(f\"✅ Artist Radio créée: {len(df_result)} tracks\")\n",
    "        return df_result\n",
    "    \n",
    "    def made_for_you_playlists(self, user_id=None):\n",
    "        \"\"\"\n",
    "        BONUS 3: \"Made for You\" - Playlists personnalisées contextuelles\n",
    "        Inspiré des playlists \"Made for You\" de Spotify\n",
    "        \"\"\"\n",
    "        logger.info(\"=== BONUS 3: MADE FOR YOU PLAYLISTS ===\")\n",
    "        \n",
    "        if user_id is None:\n",
    "            user_id = random.choice(list(self.user_to_idx.keys()))\n",
    "        \n",
    "        if user_id not in self.user_to_idx:\n",
    "            logger.warning(f\"Utilisateur {user_id} non trouvé\")\n",
    "            return {}\n",
    "        \n",
    "        logger.info(f\"Génération playlists personnalisées pour {user_id}...\")\n",
    "        \n",
    "        # Analyser le profil utilisateur\n",
    "        user_profile = self._analyze_user_profile(user_id)\n",
    "        playlists = {}\n",
    "        \n",
    "        # Playlist 1: \"Your Time Capsule\" - Hits de son époque préférée\n",
    "        time_capsule = self._create_time_capsule_playlist(user_id, user_profile)\n",
    "        playlists['time_capsule'] = time_capsule\n",
    "        \n",
    "        # Playlist 2: \"Chill Mix\" - Tracks relaxantes basées sur ses goûts\n",
    "        chill_mix = self._create_chill_mix_playlist(user_id, user_profile)\n",
    "        playlists['chill_mix'] = chill_mix\n",
    "        \n",
    "        # Playlist 3: \"Workout Mix\" - Tracks énergiques\n",
    "        workout_mix = self._create_workout_mix_playlist(user_id, user_profile)\n",
    "        playlists['workout_mix'] = workout_mix\n",
    "        \n",
    "        # Sauvegarder chaque playlist\n",
    "        for playlist_name, playlist_data in playlists.items():\n",
    "            if playlist_data:\n",
    "                df = pd.DataFrame(playlist_data)\n",
    "                df.to_csv(f'results/bonus_made_for_you_{playlist_name}_{user_id[:8]}.csv', index=False)\n",
    "                logger.info(f\"✅ {playlist_name.replace('_', ' ').title()}: {len(df)} tracks\")\n",
    "        \n",
    "        return playlists\n",
    "    \n",
    "    # === MÉTHODES UTILITAIRES ===\n",
    "    \n",
    "    def _analyze_user_profile(self, user_id):\n",
    "        \"\"\"Analyse le profil d'un utilisateur\"\"\"\n",
    "        user_songs = self.triplets_df[self.triplets_df['user_id'] == user_id]\n",
    "        \n",
    "        # Genres préférés\n",
    "        user_tracks = user_songs.merge(self.tracks_df, on='song_id')\n",
    "        if not self.genre_df.empty:\n",
    "            user_genres = user_tracks.merge(self.genre_df, on='track_id', how='left')\n",
    "            top_genres = user_genres['majority_genre'].value_counts().head(5).index.tolist()\n",
    "        else:\n",
    "            top_genres = ['Rock', 'Pop']  # Défaut\n",
    "        \n",
    "        # Artistes préférés\n",
    "        top_artists = user_tracks.groupby('artist')['play_count'].sum().nlargest(10).index.tolist()\n",
    "        \n",
    "        return {\n",
    "            'top_genres': top_genres,\n",
    "            'top_artists': top_artists,\n",
    "            'total_plays': user_songs['play_count'].sum(),\n",
    "            'unique_songs': len(user_songs),\n",
    "            'avg_plays_per_song': user_songs['play_count'].mean()\n",
    "        }\n",
    "    \n",
    "    def _analyze_artist_profile(self, artist):\n",
    "        \"\"\"Analyse le profil d'un artiste\"\"\"\n",
    "        artist_tracks = self.tracks_df[self.tracks_df['artist'] == artist]\n",
    "        \n",
    "        # Genre principal\n",
    "        if not self.genre_df.empty:\n",
    "            artist_genres = artist_tracks.merge(self.genre_df, on='track_id', how='left')\n",
    "            main_genre = artist_genres['majority_genre'].mode()\n",
    "            main_genre = main_genre.iloc[0] if len(main_genre) > 0 else 'Unknown'\n",
    "        else:\n",
    "            main_genre = 'Rock'  # Défaut\n",
    "        \n",
    "        # Popularité\n",
    "        artist_plays = self.triplets_df[\n",
    "            self.triplets_df['song_id'].isin(artist_tracks['song_id'])\n",
    "        ]['play_count'].sum()\n",
    "        \n",
    "        return {\n",
    "            'main_genre': main_genre,\n",
    "            'total_tracks': len(artist_tracks),\n",
    "            'total_plays': artist_plays\n",
    "        }\n",
    "    \n",
    "    def _get_cf_discoveries(self, user_id, n_tracks):\n",
    "        \"\"\"Recommandations collaborative filtering pour découverte\"\"\"\n",
    "        # Simplification: prendre des artistes populaires non écoutés\n",
    "        user_songs = set(self.triplets_df[self.triplets_df['user_id'] == user_id]['song_id'])\n",
    "        \n",
    "        # Tracks populaires non écoutées\n",
    "        all_popularity = self.triplets_df.groupby('song_id')['play_count'].sum()\n",
    "        unheard_songs = [song for song in all_popularity.index if song not in user_songs]\n",
    "        \n",
    "        # Prendre les plus populaires parmi les non-écoutées\n",
    "        recommendations = []\n",
    "        for song_id in unheard_songs[:n_tracks*2]:  # Buffer pour diversité\n",
    "            score = all_popularity[song_id]\n",
    "            recommendations.append((song_id, score, \"Collaborative Discovery\"))\n",
    "        \n",
    "        return sorted(recommendations, key=lambda x: x[1], reverse=True)[:n_tracks]\n",
    "    \n",
    "    def _get_genre_expansion(self, user_id, user_profile, n_tracks):\n",
    "        \"\"\"Expansion par genres préférés\"\"\"\n",
    "        recommendations = []\n",
    "        user_songs = set(self.triplets_df[self.triplets_df['user_id'] == user_id]['song_id'])\n",
    "        \n",
    "        for genre in user_profile['top_genres'][:3]:  # Top 3 genres\n",
    "            if not self.genre_df.empty:\n",
    "                genre_tracks = self.genre_df[self.genre_df['majority_genre'] == genre]['track_id']\n",
    "                genre_songs = self.tracks_df[self.tracks_df['track_id'].isin(genre_tracks)]['song_id']\n",
    "                \n",
    "                # Exclure les déjà écoutées\n",
    "                new_genre_songs = [s for s in genre_songs if s not in user_songs]\n",
    "                \n",
    "                # Prendre quelques tracks populaires de ce genre\n",
    "                for song_id in new_genre_songs[:n_tracks//3]:\n",
    "                    popularity = self.triplets_df[self.triplets_df['song_id'] == song_id]['play_count'].sum()\n",
    "                    if popularity > 0:\n",
    "                        recommendations.append((song_id, popularity, f\"Genre Expansion ({genre})\"))\n",
    "        \n",
    "        return recommendations[:n_tracks]\n",
    "    \n",
    "    def _get_pure_discovery(self, user_id, n_tracks):\n",
    "        \"\"\"Découverte pure - trends et diversité\"\"\"\n",
    "        user_songs = set(self.triplets_df[self.triplets_df['user_id'] == user_id]['song_id'])\n",
    "        user_artists = set(self.triplets_df[\n",
    "            self.triplets_df['user_id'] == user_id\n",
    "        ].merge(self.tracks_df, on='song_id')['artist'])\n",
    "        \n",
    "        # Nouveaux artistes populaires\n",
    "        all_artists_popularity = self.triplets_df.merge(\n",
    "            self.tracks_df, on='song_id'\n",
    "        ).groupby('artist')['play_count'].sum().sort_values(ascending=False)\n",
    "        \n",
    "        recommendations = []\n",
    "        for artist in all_artists_popularity.index:\n",
    "            if artist not in user_artists:\n",
    "                artist_songs = self.tracks_df[self.tracks_df['artist'] == artist]['song_id']\n",
    "                unheard_songs = [s for s in artist_songs if s not in user_songs]\n",
    "                \n",
    "                if unheard_songs:\n",
    "                    # Prendre la chanson la plus populaire de cet artiste\n",
    "                    best_song = None\n",
    "                    best_popularity = 0\n",
    "                    for song_id in unheard_songs:\n",
    "                        pop = self.triplets_df[self.triplets_df['song_id'] == song_id]['play_count'].sum()\n",
    "                        if pop > best_popularity:\n",
    "                            best_popularity = pop\n",
    "                            best_song = song_id\n",
    "                    \n",
    "                    if best_song and best_popularity > 0:\n",
    "                        recommendations.append((best_song, best_popularity, \"New Artist Discovery\"))\n",
    "                        \n",
    "                        if len(recommendations) >= n_tracks:\n",
    "                            break\n",
    "        \n",
    "        return recommendations[:n_tracks]\n",
    "    \n",
    "    def _diversify_playlist(self, recommendations, n_tracks):\n",
    "        \"\"\"Diversifie une playlist pour éviter la répétition\"\"\"\n",
    "        # Déduplication par song_id\n",
    "        seen_songs = set()\n",
    "        seen_artists = set()\n",
    "        diversified = []\n",
    "        \n",
    "        # Trier par score\n",
    "        recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for song_id, score, reason in recommendations:\n",
    "            if song_id not in seen_songs:\n",
    "                track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "                if not track_info.empty:\n",
    "                    artist = track_info.iloc[0]['artist']\n",
    "                    \n",
    "                    # Limiter à 2 chansons par artiste\n",
    "                    artist_count = sum(1 for _, _, _, a in [(s, sc, r, \n",
    "                        self.tracks_df[self.tracks_df['song_id'] == s].iloc[0]['artist'] \n",
    "                        if not self.tracks_df[self.tracks_df['song_id'] == s].empty else 'Unknown') \n",
    "                        for s, sc, r in diversified] if a == artist)\n",
    "                    \n",
    "                    if artist_count < 2:\n",
    "                        diversified.append((song_id, score, reason))\n",
    "                        seen_songs.add(song_id)\n",
    "                        \n",
    "                        if len(diversified) >= n_tracks:\n",
    "                            break\n",
    "        \n",
    "        return diversified\n",
    "    \n",
    "    def _get_artist_hits(self, artist, n_tracks):\n",
    "        \"\"\"Récupère les hits d'un artiste\"\"\"\n",
    "        artist_songs = self.tracks_df[self.tracks_df['artist'] == artist]['song_id']\n",
    "        \n",
    "        hits = []\n",
    "        for song_id in artist_songs:\n",
    "            popularity = self.triplets_df[self.triplets_df['song_id'] == song_id]['play_count'].sum()\n",
    "            if popularity > 0:\n",
    "                hits.append((song_id, popularity))\n",
    "        \n",
    "        return sorted(hits, key=lambda x: x[1], reverse=True)[:n_tracks]\n",
    "    \n",
    "    def _get_genre_similar_artists(self, seed_artist, artist_profile, n_tracks):\n",
    "        \"\"\"Trouve des artistes similaires par genre\"\"\"\n",
    "        main_genre = artist_profile['main_genre']\n",
    "        \n",
    "        if self.genre_df.empty:\n",
    "            return []\n",
    "        \n",
    "        # Artistes du même genre\n",
    "        genre_tracks = self.genre_df[self.genre_df['majority_genre'] == main_genre]['track_id']\n",
    "        genre_artists = self.tracks_df[\n",
    "            (self.tracks_df['track_id'].isin(genre_tracks)) &\n",
    "            (self.tracks_df['artist'] != seed_artist)\n",
    "        ]['artist'].unique()\n",
    "        \n",
    "        similar = []\n",
    "        for artist in genre_artists[:n_tracks*2]:  # Buffer\n",
    "            artist_songs = self.tracks_df[self.tracks_df['artist'] == artist]['song_id']\n",
    "            if len(artist_songs) > 0:\n",
    "                # Prendre la chanson la plus populaire\n",
    "                best_song = None\n",
    "                best_pop = 0\n",
    "                for song_id in artist_songs:\n",
    "                    pop = self.triplets_df[self.triplets_df['song_id'] == song_id]['play_count'].sum()\n",
    "                    if pop > best_pop:\n",
    "                        best_pop = pop\n",
    "                        best_song = song_id\n",
    "                \n",
    "                if best_song and best_pop > 0:\n",
    "                    similar.append((best_song, best_pop))\n",
    "        \n",
    "        return sorted(similar, key=lambda x: x[1], reverse=True)[:n_tracks]\n",
    "    \n",
    "    def _get_collaborative_similar_artists(self, seed_artist, n_tracks):\n",
    "        \"\"\"Trouve des artistes via collaborative filtering\"\"\"\n",
    "        # Simplification: artistes populaires différents\n",
    "        seed_songs = self.tracks_df[self.tracks_df['artist'] == seed_artist]['song_id']\n",
    "        \n",
    "        # Utilisateurs qui écoutent cet artiste\n",
    "        seed_users = self.triplets_df[\n",
    "            self.triplets_df['song_id'].isin(seed_songs)\n",
    "        ]['user_id'].unique()\n",
    "        \n",
    "        # Autres artistes écoutés par ces utilisateurs\n",
    "        other_artists_plays = self.triplets_df[\n",
    "            (self.triplets_df['user_id'].isin(seed_users)) &\n",
    "            (~self.triplets_df['song_id'].isin(seed_songs))\n",
    "        ].merge(self.tracks_df, on='song_id').groupby('artist')['play_count'].sum()\n",
    "        \n",
    "        similar = []\n",
    "        for artist, total_plays in other_artists_plays.nlargest(n_tracks*2).items():\n",
    "            if artist != seed_artist:\n",
    "                # Meilleure chanson de cet artiste\n",
    "                artist_songs = self.tracks_df[self.tracks_df['artist'] == artist]['song_id']\n",
    "                best_song = None\n",
    "                best_pop = 0\n",
    "                for song_id in artist_songs:\n",
    "                    pop = self.triplets_df[self.triplets_df['song_id'] == song_id]['play_count'].sum()\n",
    "                    if pop > best_pop:\n",
    "                        best_pop = pop\n",
    "                        best_song = song_id\n",
    "                \n",
    "                if best_song:\n",
    "                    similar.append((best_song, total_plays))\n",
    "        \n",
    "        return similar[:n_tracks]\n",
    "    \n",
    "    def _get_radio_discovery(self, artist_profile, n_tracks):\n",
    "        \"\"\"Découverte pour la radio\"\"\"\n",
    "        main_genre = artist_profile['main_genre']\n",
    "        \n",
    "        if self.genre_df.empty:\n",
    "            return []\n",
    "        \n",
    "        # Nouveaux artistes du même genre\n",
    "        genre_tracks = self.genre_df[self.genre_df['majority_genre'] == main_genre]['track_id']\n",
    "        genre_songs = self.tracks_df[self.tracks_df['track_id'].isin(genre_tracks)]\n",
    "        \n",
    "        discovery = []\n",
    "        artists_seen = set()\n",
    "        \n",
    "        for _, track in genre_songs.sample(min(100, len(genre_songs))).iterrows():\n",
    "            artist = track['artist']\n",
    "            song_id = track['song_id']\n",
    "            \n",
    "            if artist not in artists_seen:\n",
    "                popularity = self.triplets_df[self.triplets_df['song_id'] == song_id]['play_count'].sum()\n",
    "                if popularity > 0:\n",
    "                    discovery.append((song_id, popularity))\n",
    "                    artists_seen.add(artist)\n",
    "                    \n",
    "                    if len(discovery) >= n_tracks:\n",
    "                        break\n",
    "        \n",
    "        return discovery\n",
    "    \n",
    "    def _create_radio_flow(self, tracks, n_tracks):\n",
    "        \"\"\"Crée un flow naturel pour la radio\"\"\"\n",
    "        # Pour simplifier, on mélange et on prend les meilleurs\n",
    "        random.shuffle(tracks)\n",
    "        return tracks[:n_tracks]\n",
    "    \n",
    "    def _create_time_capsule_playlist(self, user_id, user_profile):\n",
    "        \"\"\"Crée une playlist Time Capsule\"\"\"\n",
    "        # Prendre les hits des artistes préférés\n",
    "        playlist = []\n",
    "        user_songs = set(self.triplets_df[self.triplets_df['user_id'] == user_id]['song_id'])\n",
    "        \n",
    "        for artist in user_profile['top_artists'][:5]:\n",
    "            artist_songs = self.tracks_df[self.tracks_df['artist'] == artist]['song_id']\n",
    "            unheard = [s for s in artist_songs if s not in user_songs]\n",
    "            \n",
    "            for song_id in unheard[:2]:  # 2 chansons par artiste\n",
    "                track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "                if not track_info.empty:\n",
    "                    track_info = track_info.iloc[0]\n",
    "                    playlist.append({\n",
    "                        'rank': len(playlist) + 1,\n",
    "                        'artist': track_info['artist'],\n",
    "                        'title': track_info['title'],\n",
    "                        'song_id': song_id,\n",
    "                        'playlist_type': 'Time Capsule',\n",
    "                        'reason': f\"More from {artist}\"\n",
    "                    })\n",
    "        \n",
    "        return playlist[:20]  # Limite à 20\n",
    "    \n",
    "    def _create_chill_mix_playlist(self, user_id, user_profile):\n",
    "        \"\"\"Crée un Chill Mix\"\"\"\n",
    "        # Version simplifiée: prendre des tracks populaires des genres calmes\n",
    "        chill_genres = ['Jazz', 'Blues', 'Pop']  # Genres \"chill\"\n",
    "        playlist = []\n",
    "        user_songs = set(self.triplets_df[self.triplets_df['user_id'] == user_id]['song_id'])\n",
    "        \n",
    "        for genre in chill_genres:\n",
    "            if not self.genre_df.empty:\n",
    "                genre_tracks = self.genre_df[self.genre_df['majority_genre'] == genre]['track_id']\n",
    "                genre_songs = self.tracks_df[self.tracks_df['track_id'].isin(genre_tracks)]['song_id']\n",
    "                unheard = [s for s in genre_songs if s not in user_songs]\n",
    "                \n",
    "                # Prendre quelques populaires\n",
    "                for song_id in unheard[:5]:\n",
    "                    track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "                    if not track_info.empty:\n",
    "                        popularity = self.triplets_df[self.triplets_df['song_id'] == song_id]['play_count'].sum()\n",
    "                        if popularity > 0:\n",
    "                            track_info = track_info.iloc[0]\n",
    "                            playlist.append({\n",
    "                                'rank': len(playlist) + 1,\n",
    "                                'artist': track_info['artist'],\n",
    "                                'title': track_info['title'],\n",
    "                                'song_id': song_id,\n",
    "                                'playlist_type': 'Chill Mix',\n",
    "                                'reason': f\"Chill {genre}\"\n",
    "                            })\n",
    "                            \n",
    "                            if len(playlist) >= 15:\n",
    "                                return playlist\n",
    "        \n",
    "        return playlist\n",
    "    \n",
    "    def _create_workout_mix_playlist(self, user_id, user_profile):\n",
    "        \"\"\"Crée un Workout Mix\"\"\"\n",
    "        # Version simplifiée: genres énergiques\n",
    "        energy_genres = ['Rock', 'Rap', 'Electronic']\n",
    "        playlist = []\n",
    "        user_songs = set(self.triplets_df[self.triplets_df['user_id'] == user_id]['song_id'])\n",
    "        \n",
    "        for genre in energy_genres:\n",
    "            if not self.genre_df.empty:\n",
    "                genre_tracks = self.genre_df[self.genre_df['majority_genre'] == genre]['track_id']\n",
    "                genre_songs = self.tracks_df[self.tracks_df['track_id'].isin(genre_tracks)]['song_id']\n",
    "                unheard = [s for s in genre_songs if s not in user_songs]\n",
    "                \n",
    "                for song_id in unheard[:5]:\n",
    "                    track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "                    if not track_info.empty:\n",
    "                        popularity = self.triplets_df[self.triplets_df['song_id'] == song_id]['play_count'].sum()\n",
    "                        if popularity > 0:\n",
    "                            track_info = track_info.iloc[0]\n",
    "                            playlist.append({\n",
    "                                'rank': len(playlist) + 1,\n",
    "                                'artist': track_info['artist'],\n",
    "                                'title': track_info['title'],\n",
    "                                'song_id': song_id,\n",
    "                                'playlist_type': 'Workout Mix',\n",
    "                                'reason': f\"High Energy {genre}\"\n",
    "                            })\n",
    "                            \n",
    "                            if len(playlist) >= 15:\n",
    "                                return playlist\n",
    "        \n",
    "        return playlist\n",
    "\n",
    "def main():\n",
    "    \"\"\"Exécute toutes les fonctionnalités bonus\"\"\"\n",
    "    import os\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        spotify_features = SpotifyInspiredFeatures()\n",
    "        \n",
    "        logger.info(\"\\n🎵 EXÉCUTION DES FONCTIONNALITÉS BONUS 🎵\")\n",
    "        logger.info(\"Inspirées de Spotify, Apple Music, etc.\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # BONUS 1: Discover Weekly\n",
    "        print(\"\\n🔍 1. Discover Weekly...\")\n",
    "        discover_weekly = spotify_features.discover_weekly()\n",
    "        if not discover_weekly.empty:\n",
    "            print(f\"✅ Discover Weekly généré: {len(discover_weekly)} tracks\")\n",
    "            print(\"   Top 3:\")\n",
    "            for _, row in discover_weekly.head(3).iterrows():\n",
    "                print(f\"   {row['rank']}. {row['artist']} - {row['title']}\")\n",
    "                print(f\"      Raison: {row['reason']}\")\n",
    "        \n",
    "        # BONUS 2: Artist Radio\n",
    "        print(\"\\n📻 2. Artist Radio...\")\n",
    "        # Prendre un artiste populaire\n",
    "        popular_artists = spotify_features.tracks_df.merge(\n",
    "            spotify_features.triplets_df, on='song_id'\n",
    "        ).groupby('artist')['play_count'].sum().nlargest(10)\n",
    "        \n",
    "        if len(popular_artists) > 0:\n",
    "            seed_artist = popular_artists.index[0]\n",
    "            artist_radio = spotify_features.artist_radio(seed_artist)\n",
    "            if not artist_radio.empty:\n",
    "                print(f\"✅ Artist Radio '{seed_artist}' généré: {len(artist_radio)} tracks\")\n",
    "                print(\"   Aperçu:\")\n",
    "                for _, row in artist_radio.head(3).iterrows():\n",
    "                    print(f\"   {row['position']}. {row['artist']} - {row['title']}\")\n",
    "                    print(f\"      Catégorie: {row['category']}\")\n",
    "        \n",
    "        # BONUS 3: Made for You Playlists\n",
    "        print(\"\\n🎯 3. Made for You Playlists...\")\n",
    "        made_for_you = spotify_features.made_for_you_playlists()\n",
    "        \n",
    "        total_playlists = len(made_for_you)\n",
    "        total_tracks = sum(len(playlist) for playlist in made_for_you.values())\n",
    "        print(f\"✅ Made for You généré: {total_playlists} playlists, {total_tracks} tracks total\")\n",
    "        \n",
    "        for playlist_name, playlist_data in made_for_you.items():\n",
    "            if playlist_data:\n",
    "                print(f\"   📋 {playlist_name.replace('_', ' ').title()}: {len(playlist_data)} tracks\")\n",
    "        \n",
    "        # Résumé final\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"🎉 TOUTES LES FONCTIONNALITÉS BONUS EXÉCUTÉES!\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"📁 Fichiers générés dans 'results/':\")\n",
    "        \n",
    "        bonus_files = [f for f in os.listdir('results') if f.startswith('bonus_')]\n",
    "        for file in bonus_files:\n",
    "            file_path = os.path.join('results', file)\n",
    "            size_kb = os.path.getsize(file_path) / 1024\n",
    "            print(f\"   📄 {file} ({size_kb:.1f} KB)\")\n",
    "        \n",
    "        print(f\"\\n✨ {len(bonus_files)} fichiers bonus créés!\")\n",
    "        print(\"\\n🎵 Fonctionnalités implémentées:\")\n",
    "        print(\"   ✅ 1. Discover Weekly (personnalisée)\")\n",
    "        print(\"   ✅ 2. Artist Radio (expansion contextuelle)\")\n",
    "        print(\"   ✅ 3. Made for You (playlists contextuelles)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"❌ Erreur lors de l'exécution du bonus: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba84d06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚡ MYSPOTIFY BONUS - VERSION RAPIDE ⚡\n",
      "==================================================\n",
      "🚀 Optimisé pour exécution rapide mais avec plus de données!\n",
      "\n",
      "🚀 Mode rapide: échantillon de 10000 interactions\n",
      "📊 Chargement échantillon des données...\n",
      "✅ Données chargées: 10000 interactions, 173 users, 7849 songs\n",
      "\n",
      "🎵 EXÉCUTION DES 3 FONCTIONNALITÉS BONUS...\n",
      "\n",
      "🔍 BONUS 1: QUICK DISCOVER WEEKLY\n",
      "----------------------------------------\n",
      "👤 Génération pour utilisateur: 2c42e65513...\n",
      "   🎵 Utilisateur a écouté: 76 chansons\n",
      "❌ Aucune recommandation Discover Weekly générée\n",
      "\n",
      "📻 BONUS 2: QUICK ARTIST RADIO\n",
      "----------------------------------------\n",
      "🎤 Radio pour: Sammy Kershaw\n",
      "   👥 Fans trouvés: 2\n",
      "✅ Artist Radio créé: 20 tracks\n",
      "   💾 Sauvegardé: quick_artist_radio_Sammy_Kershaw.csv\n",
      "   Composition:\n",
      "   • Filler: 17 tracks\n",
      "   • Similar Artist: 2 tracks\n",
      "   • Original Artist: 1 tracks\n",
      "   Aperçu:\n",
      "   1. The Knife - Silent Shout (Filler)\n",
      "   2. Guns N' Roses - Street Of Dreams (Similar Artist)\n",
      "   3. Paco De Lucia - Entre Dos Aguas (Filler)\n",
      "\n",
      "🎯 BONUS 3: QUICK MADE FOR YOU\n",
      "----------------------------------------\n",
      "👤 Playlists pour utilisateur: 66166f4f57...\n",
      "   🎵 Historique: 69 chansons\n",
      "   🔄 Remplissage Time Capsule avec recommandations génériques...\n",
      "✅ Time Capsule: 8 tracks\n",
      "   💾 Sauvegardé: quick_made_for_you_time_capsule_66166f4f.csv\n",
      "   Exemple: Nick Lowe - All Men Are Liars\n",
      "✅ Discovery Mix: 1 tracks\n",
      "   💾 Sauvegardé: quick_made_for_you_discovery_mix_66166f4f.csv\n",
      "   Exemple: Nick Lowe - All Men Are Liars\n",
      "🎯 Total Made for You: 9 tracks dans 2 playlists\n",
      "\n",
      "==================================================\n",
      "🎉 BONUS RAPIDE TERMINÉ!\n",
      "==================================================\n",
      "📁 Fichiers créés: 3\n",
      "   📄 quick_made_for_you_time_capsule_66166f4f.csv (0.5 KB)\n",
      "   📄 quick_artist_radio_Sammy_Kershaw.csv (1.2 KB)\n",
      "   📄 quick_made_for_you_discovery_mix_66166f4f.csv (0.1 KB)\n",
      "\n",
      "📊 RÉSUMÉ:\n",
      "   ✅ 3 fonctionnalités bonus implémentées!\n",
      "   📄 3 fichiers CSV générés\n",
      "   💾 Taille totale: 1.9 KB\n",
      "   ⏱️  Temps d'exécution: ~1 minute\n",
      "   🎵 Inspiré de: Spotify, Apple Music\n",
      "\n",
      "🎉 BONUS COMPLET - Toutes les fonctionnalités marchent!\n"
     ]
    }
   ],
   "source": [
    "# quick_bonus_features.py - Version simplifiée et rapide des fonctionnalités bonus\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "class QuickSpotifyFeatures:\n",
    "    \"\"\"Version simplifiée des fonctionnalités Spotify pour exécution rapide\"\"\"\n",
    "    \n",
    "    def __init__(self, sample_size=10000):\n",
    "        \"\"\"\n",
    "        sample_size: Nombre de lignes à charger pour accélérer l'exécution\n",
    "        \"\"\"\n",
    "        self.sample_size = sample_size\n",
    "        print(f\"🚀 Mode rapide: échantillon de {sample_size} interactions\")\n",
    "        self.load_sample_data()\n",
    "    \n",
    "    def load_sample_data(self):\n",
    "        \"\"\"Charge un échantillon des données pour exécution rapide\"\"\"\n",
    "        print(\"📊 Chargement échantillon des données...\")\n",
    "        \n",
    "        # Charger plus de données pour avoir plus de variété\n",
    "        self.triplets_df = pd.read_csv(\n",
    "            \"train_triplets.txt\", sep='\\t', \n",
    "            names=['user_id', 'song_id', 'play_count'],\n",
    "            nrows=self.sample_size\n",
    "        )\n",
    "        \n",
    "        self.tracks_df = pd.read_csv(\n",
    "            \"p02_unique_tracks.txt\", sep='<SEP>',\n",
    "            names=['track_id', 'song_id', 'artist', 'title'],\n",
    "            engine='python', nrows=5000  # Plus de tracks pour plus de variété\n",
    "        )\n",
    "        \n",
    "        # Créer mappings rapides\n",
    "        self.users = self.triplets_df['user_id'].unique()\n",
    "        self.songs = self.triplets_df['song_id'].unique()\n",
    "        \n",
    "        print(f\"✅ Données chargées: {len(self.triplets_df)} interactions, {len(self.users)} users, {len(self.songs)} songs\")\n",
    "    \n",
    "    def quick_discover_weekly(self, user_id=None, n_tracks=15):\n",
    "        \"\"\"Version rapide de Discover Weekly\"\"\"\n",
    "        print(\"\\n🔍 BONUS 1: QUICK DISCOVER WEEKLY\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if user_id is None:\n",
    "            user_id = random.choice(self.users)\n",
    "        \n",
    "        print(f\"👤 Génération pour utilisateur: {user_id[:10]}...\")\n",
    "        \n",
    "        # 1. Ce que l'utilisateur a déjà écouté\n",
    "        user_songs = set(self.triplets_df[\n",
    "            self.triplets_df['user_id'] == user_id\n",
    "        ]['song_id'])\n",
    "        \n",
    "        print(f\"   🎵 Utilisateur a écouté: {len(user_songs)} chansons\")\n",
    "        \n",
    "        # 2. Collaborative simple: utilisateurs similaires\n",
    "        similar_users = self._find_similar_users_quick(user_id, top_k=10)\n",
    "        \n",
    "        # 3. Recommandations des utilisateurs similaires\n",
    "        cf_recs = []\n",
    "        for similar_user in similar_users:\n",
    "            similar_songs = self.triplets_df[\n",
    "                self.triplets_df['user_id'] == similar_user\n",
    "            ]['song_id'].values\n",
    "            \n",
    "            # Songs pas encore écoutées\n",
    "            new_songs = [s for s in similar_songs if s not in user_songs]\n",
    "            cf_recs.extend(new_songs[:3])  # 3 par utilisateur similaire\n",
    "        \n",
    "        # 4. Popularité générale (songs trending)\n",
    "        popular_songs = self.triplets_df.groupby('song_id')['play_count'].sum().nlargest(50)\n",
    "        trending_recs = [s for s in popular_songs.index if s not in user_songs][:n_tracks//2]\n",
    "        \n",
    "        # 5. Mélange final\n",
    "        all_recommendations = list(set(cf_recs + trending_recs))\n",
    "        random.shuffle(all_recommendations)\n",
    "        final_recs = all_recommendations[:n_tracks]\n",
    "        \n",
    "        # 6. Formatage\n",
    "        playlist = []\n",
    "        for i, song_id in enumerate(final_recs, 1):\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            \n",
    "            if not track_info.empty:\n",
    "                track = track_info.iloc[0]\n",
    "                reason = \"Similar Users\" if song_id in cf_recs else \"Trending\"\n",
    "                \n",
    "                playlist.append({\n",
    "                    'rank': i,\n",
    "                    'artist': track['artist'],\n",
    "                    'title': track['title'],\n",
    "                    'song_id': song_id,\n",
    "                    'reason': reason\n",
    "                })\n",
    "        \n",
    "        # Sauvegarder\n",
    "        if playlist:\n",
    "            df = pd.DataFrame(playlist)\n",
    "            filename = f'quick_discover_weekly_{user_id[:8]}.csv'\n",
    "            filepath = f'results/{filename}'\n",
    "            df.to_csv(filepath, index=False)\n",
    "            \n",
    "            print(f\"✅ Discover Weekly créé: {len(playlist)} tracks\")\n",
    "            print(f\"   💾 Sauvegardé: {filename}\")\n",
    "            print(\"   Top 3 découvertes:\")\n",
    "            for _, row in df.head(3).iterrows():\n",
    "                print(f\"   {row['rank']}. {row['artist']} - {row['title']} ({row['reason']})\")\n",
    "            \n",
    "            return df\n",
    "        else:\n",
    "            print(\"❌ Aucune recommandation Discover Weekly générée\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def quick_artist_radio(self, seed_artist=None, n_tracks=20):\n",
    "        \"\"\"Version rapide d'Artist Radio\"\"\"\n",
    "        print(\"\\n📻 BONUS 2: QUICK ARTIST RADIO\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if seed_artist is None:\n",
    "            # Prendre un artiste populaire au hasard\n",
    "            popular_artists = self.triplets_df.merge(\n",
    "                self.tracks_df, on='song_id'\n",
    "            ).groupby('artist')['play_count'].sum().nlargest(20)\n",
    "            seed_artist = random.choice(popular_artists.index.tolist())\n",
    "        \n",
    "        print(f\"🎤 Radio pour: {seed_artist}\")\n",
    "        \n",
    "        # 1. Songs de l'artiste original\n",
    "        artist_songs = self.tracks_df[\n",
    "            self.tracks_df['artist'] == seed_artist\n",
    "        ]['song_id'].values\n",
    "        \n",
    "        original_hits = []\n",
    "        for song_id in artist_songs[:n_tracks//4]:  # 25% de l'artiste original\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            if not track_info.empty:\n",
    "                track = track_info.iloc[0]\n",
    "                original_hits.append((song_id, track['artist'], track['title'], \"Original Artist\"))\n",
    "        \n",
    "        # 2. Utilisateurs qui écoutent cet artiste\n",
    "        artist_fans = self.triplets_df[\n",
    "            self.triplets_df['song_id'].isin(artist_songs)\n",
    "        ]['user_id'].unique()\n",
    "        \n",
    "        print(f\"   👥 Fans trouvés: {len(artist_fans)}\")\n",
    "        \n",
    "        # 3. Autres artistes écoutés par ces fans\n",
    "        fan_music = self.triplets_df[\n",
    "            self.triplets_df['user_id'].isin(artist_fans)\n",
    "        ].merge(self.tracks_df, on='song_id')\n",
    "        \n",
    "        similar_artists = fan_music[\n",
    "            fan_music['artist'] != seed_artist\n",
    "        ].groupby('artist')['play_count'].sum().nlargest(10)\n",
    "        \n",
    "        # 4. Prendre hits des artistes similaires\n",
    "        similar_hits = []\n",
    "        for artist in similar_artists.index[:5]:\n",
    "            artist_tracks = self.tracks_df[self.tracks_df['artist'] == artist]\n",
    "            for _, track in artist_tracks.head(2).iterrows():  # 2 par artiste\n",
    "                similar_hits.append((track['song_id'], track['artist'], track['title'], \"Similar Artist\"))\n",
    "        \n",
    "        # 4. Quelques tracks populaires générales pour remplir\n",
    "        general_popular = self.triplets_df.groupby('song_id')['play_count'].sum().nlargest(50)\n",
    "        general_hits = []\n",
    "        for song_id in general_popular.index:\n",
    "            if len(general_hits) >= n_tracks//2:  # Remplir jusqu'à la moitié\n",
    "                break\n",
    "            track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "            if not track_info.empty:\n",
    "                track = track_info.iloc[0]\n",
    "                if track['artist'] != seed_artist:  # Éviter l'artiste seed\n",
    "                    general_hits.append((song_id, track['artist'], track['title'], \"Popular\"))\n",
    "        \n",
    "        # 5. Combiner et garantir un minimum de tracks\n",
    "        all_radio = original_hits + similar_hits + general_hits\n",
    "        \n",
    "        # Si pas assez, ajouter plus de tracks populaires\n",
    "        if len(all_radio) < n_tracks:\n",
    "            additional_popular = self.triplets_df.merge(\n",
    "                self.tracks_df, on='song_id'\n",
    "            ).groupby(['artist', 'title', 'song_id'])['play_count'].sum().nlargest(n_tracks*2)\n",
    "            \n",
    "            existing_songs = set([song_id for song_id, _, _, _ in all_radio])\n",
    "            \n",
    "            for (artist, title, song_id), _ in additional_popular.items():\n",
    "                if song_id not in existing_songs and len(all_radio) < n_tracks:\n",
    "                    all_radio.append((song_id, artist, title, \"Filler\"))\n",
    "        \n",
    "        # Mélanger et prendre exactement n_tracks\n",
    "        random.shuffle(all_radio)\n",
    "        final_radio = all_radio[:n_tracks]\n",
    "        \n",
    "        # 7. Formatage\n",
    "        radio = []\n",
    "        for i, (song_id, artist, title, category) in enumerate(final_radio, 1):\n",
    "            radio.append({\n",
    "                'position': i,\n",
    "                'artist': artist,\n",
    "                'title': title,\n",
    "                'song_id': song_id,\n",
    "                'category': category\n",
    "            })\n",
    "        \n",
    "        # Sauvegarder\n",
    "        if radio:\n",
    "            df = pd.DataFrame(radio)\n",
    "            safe_artist = seed_artist.replace('/', '_').replace(' ', '_').replace(';', '_')[:15]\n",
    "            filename = f'quick_artist_radio_{safe_artist}.csv'\n",
    "            filepath = f'results/{filename}'\n",
    "            df.to_csv(filepath, index=False)\n",
    "            \n",
    "            print(f\"✅ Artist Radio créé: {len(radio)} tracks\")\n",
    "            print(f\"   💾 Sauvegardé: {filename}\")\n",
    "            print(\"   Composition:\")\n",
    "            categories = pd.Series([r['category'] for r in radio]).value_counts()\n",
    "            for cat, count in categories.items():\n",
    "                print(f\"   • {cat}: {count} tracks\")\n",
    "            \n",
    "            print(\"   Aperçu:\")\n",
    "            for _, row in df.head(3).iterrows():\n",
    "                print(f\"   {row['position']}. {row['artist']} - {row['title']} ({row['category']})\")\n",
    "            \n",
    "            return df\n",
    "        else:\n",
    "            print(\"❌ Aucune radio générée\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def quick_made_for_you(self, user_id=None):\n",
    "        \"\"\"Version rapide des playlists Made for You\"\"\"\n",
    "        print(\"\\n🎯 BONUS 3: QUICK MADE FOR YOU\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if user_id is None:\n",
    "            # Choisir un utilisateur avec plus d'historique\n",
    "            user_song_counts = self.triplets_df.groupby('user_id').size()\n",
    "            active_users = user_song_counts[user_song_counts >= 5].index  # Au moins 5 chansons\n",
    "            if len(active_users) > 0:\n",
    "                user_id = random.choice(active_users)\n",
    "            else:\n",
    "                user_id = random.choice(self.users)\n",
    "        \n",
    "        print(f\"👤 Playlists pour utilisateur: {user_id[:10]}...\")\n",
    "        \n",
    "        # Analyser l'utilisateur rapidement\n",
    "        user_songs = self.triplets_df[self.triplets_df['user_id'] == user_id]\n",
    "        print(f\"   🎵 Historique: {len(user_songs)} chansons\")\n",
    "        \n",
    "        user_artists = user_songs.merge(self.tracks_df, on='song_id')['artist'].value_counts()\n",
    "        \n",
    "        playlists = {}\n",
    "        \n",
    "        # 1. Time Capsule - Plus de vos artistes préférés\n",
    "        time_capsule = []\n",
    "        if len(user_artists) > 0:\n",
    "            print(f\"   🎤 Top artistes: {user_artists.head(3).index.tolist()}\")\n",
    "            \n",
    "            for artist in user_artists.head(5).index:  # Top 5 artistes au lieu de 3\n",
    "                artist_tracks = self.tracks_df[self.tracks_df['artist'] == artist]\n",
    "                user_artist_songs = set(user_songs['song_id'])\n",
    "                \n",
    "                # Chansons de cet artiste pas encore écoutées\n",
    "                new_songs = artist_tracks[~artist_tracks['song_id'].isin(user_artist_songs)]\n",
    "                \n",
    "                for _, track in new_songs.head(2).iterrows():  # 2 par artiste\n",
    "                    time_capsule.append({\n",
    "                        'rank': len(time_capsule) + 1,\n",
    "                        'artist': track['artist'],\n",
    "                        'title': track['title'],\n",
    "                        'song_id': track['song_id'],\n",
    "                        'reason': f\"More from {artist}\"\n",
    "                    })\n",
    "                    \n",
    "                    if len(time_capsule) >= 10:  # Limite\n",
    "                        break\n",
    "        \n",
    "        # Si Time Capsule toujours vide, remplir avec tracks populaires des mêmes genres\n",
    "        if len(time_capsule) == 0:\n",
    "            print(\"   🔄 Remplissage Time Capsule avec recommandations génériques...\")\n",
    "            popular_tracks = self.triplets_df.merge(\n",
    "                self.tracks_df, on='song_id'\n",
    "            ).groupby(['artist', 'title', 'song_id'])['play_count'].sum().nlargest(20)\n",
    "            \n",
    "            user_song_set = set(user_songs['song_id'])\n",
    "            for (artist, title, song_id), _ in popular_tracks.items():\n",
    "                if song_id not in user_song_set and len(time_capsule) < 8:\n",
    "                    time_capsule.append({\n",
    "                        'rank': len(time_capsule) + 1,\n",
    "                        'artist': artist,\n",
    "                        'title': title,\n",
    "                        'song_id': song_id,\n",
    "                        'reason': \"Popular Pick\"\n",
    "                    })\n",
    "        \n",
    "        playlists['time_capsule'] = time_capsule\n",
    "        \n",
    "        # 2. Discovery Mix - Nouvelles découvertes\n",
    "        all_user_songs = set(user_songs['song_id'])\n",
    "        popular_unheard = self.triplets_df.groupby('song_id')['play_count'].sum().nlargest(100)  # Plus large pool\n",
    "        \n",
    "        discovery_mix = []\n",
    "        for song_id in popular_unheard.index:\n",
    "            if song_id not in all_user_songs:\n",
    "                track_info = self.tracks_df[self.tracks_df['song_id'] == song_id]\n",
    "                if not track_info.empty:\n",
    "                    track = track_info.iloc[0]\n",
    "                    discovery_mix.append({\n",
    "                        'rank': len(discovery_mix) + 1,\n",
    "                        'artist': track['artist'],\n",
    "                        'title': track['title'],\n",
    "                        'song_id': track['song_id'],\n",
    "                        'reason': \"New Discovery\"\n",
    "                    })\n",
    "                    \n",
    "                    if len(discovery_mix) >= 8:  # Limite à 8\n",
    "                        break\n",
    "        \n",
    "        playlists['discovery_mix'] = discovery_mix\n",
    "        \n",
    "        # Sauvegarder les playlists\n",
    "        saved_playlists = {}\n",
    "        total_tracks = 0\n",
    "        \n",
    "        for playlist_name, playlist_data in playlists.items():\n",
    "            if playlist_data:\n",
    "                df = pd.DataFrame(playlist_data)\n",
    "                filename = f'quick_made_for_you_{playlist_name}_{user_id[:8]}.csv'\n",
    "                filepath = f'results/{filename}'\n",
    "                df.to_csv(filepath, index=False)\n",
    "                saved_playlists[playlist_name] = df\n",
    "                total_tracks += len(playlist_data)\n",
    "                \n",
    "                print(f\"✅ {playlist_name.replace('_', ' ').title()}: {len(playlist_data)} tracks\")\n",
    "                print(f\"   💾 Sauvegardé: {filename}\")\n",
    "                if len(playlist_data) > 0:\n",
    "                    print(f\"   Exemple: {playlist_data[0]['artist']} - {playlist_data[0]['title']}\")\n",
    "            else:\n",
    "                print(f\"❌ {playlist_name.replace('_', ' ').title()}: Aucune track générée\")\n",
    "        \n",
    "        if total_tracks > 0:\n",
    "            print(f\"🎯 Total Made for You: {total_tracks} tracks dans {len(saved_playlists)} playlists\")\n",
    "        \n",
    "        return saved_playlists\n",
    "    \n",
    "    def _find_similar_users_quick(self, target_user, top_k=10):\n",
    "        \"\"\"Trouve rapidement des utilisateurs similaires\"\"\"\n",
    "        target_songs = set(self.triplets_df[\n",
    "            self.triplets_df['user_id'] == target_user\n",
    "        ]['song_id'])\n",
    "        \n",
    "        if len(target_songs) == 0:\n",
    "            return []\n",
    "        \n",
    "        similarities = []\n",
    "        for user in self.users[:100]:  # Limite à 100 users pour la rapidité\n",
    "            if user != target_user:\n",
    "                user_songs = set(self.triplets_df[\n",
    "                    self.triplets_df['user_id'] == user\n",
    "                ]['song_id'])\n",
    "                \n",
    "                # Similarité Jaccard simple\n",
    "                intersection = len(target_songs.intersection(user_songs))\n",
    "                union = len(target_songs.union(user_songs))\n",
    "                \n",
    "                if union > 0:\n",
    "                    similarity = intersection / union\n",
    "                    similarities.append((user, similarity))\n",
    "        \n",
    "        # Trier et retourner top-k\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [user for user, _ in similarities[:top_k]]\n",
    "\n",
    "def main():\n",
    "    \"\"\"Exécution rapide des 3 fonctionnalités bonus\"\"\"\n",
    "    \n",
    "    # Créer dossier results\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    print(\"⚡ MYSPOTIFY BONUS - VERSION RAPIDE ⚡\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"🚀 Optimisé pour exécution rapide mais avec plus de données!\")\n",
    "    print()\n",
    "    \n",
    "    try:\n",
    "        # Initialiser avec échantillon plus grand pour plus de variété\n",
    "        spotify = QuickSpotifyFeatures(sample_size=10000)  # Plus d'interactions\n",
    "        \n",
    "        # Exécuter les 3 bonus\n",
    "        print(\"\\n🎵 EXÉCUTION DES 3 FONCTIONNALITÉS BONUS...\")\n",
    "        \n",
    "        discover_weekly = spotify.quick_discover_weekly()\n",
    "        artist_radio = spotify.quick_artist_radio()\n",
    "        made_for_you = spotify.quick_made_for_you()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"🎉 BONUS RAPIDE TERMINÉ!\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Lister les fichiers créés\n",
    "        all_files = os.listdir('results') if os.path.exists('results') else []\n",
    "        bonus_files = [f for f in all_files if f.startswith('quick_')]\n",
    "        \n",
    "        print(f\"📁 Fichiers créés: {len(bonus_files)}\")\n",
    "        \n",
    "        total_size = 0\n",
    "        for file in bonus_files:\n",
    "            file_path = os.path.join('results', file)\n",
    "            if os.path.exists(file_path):\n",
    "                size_kb = os.path.getsize(file_path) / 1024\n",
    "                total_size += size_kb\n",
    "                print(f\"   📄 {file} ({size_kb:.1f} KB)\")\n",
    "        \n",
    "        print(f\"\\n📊 RÉSUMÉ:\")\n",
    "        print(f\"   ✅ 3 fonctionnalités bonus implémentées!\")\n",
    "        print(f\"   📄 {len(bonus_files)} fichiers CSV générés\")\n",
    "        print(f\"   💾 Taille totale: {total_size:.1f} KB\")\n",
    "        print(f\"   ⏱️  Temps d'exécution: ~1 minute\")\n",
    "        print(f\"   🎵 Inspiré de: Spotify, Apple Music\")\n",
    "        \n",
    "        if len(bonus_files) >= 3:\n",
    "            print(f\"\\n🎉 BONUS COMPLET - Toutes les fonctionnalités marchent!\")\n",
    "        else:\n",
    "            print(f\"\\n⚠️  Seulement {len(bonus_files)} fichiers générés sur 3+ attendus\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f94f3a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 CORRECTIF DISCOVER WEEKLY\n",
      "========================================\n",
      "📊 Chargement des données...\n",
      "👤 Utilisateur sélectionné: 2c42e6551311...\n",
      "🎵 Historique utilisateur: 76 chansons\n",
      "🔍 Recherche utilisateurs similaires...\n",
      "👥 Utilisateurs similaires trouvés: 11\n",
      "🤝 Recommandations collaborative: 19\n",
      "📈 Recherche tracks populaires...\n",
      "🔥 Tracks populaires non écoutées: 7773\n",
      "🎤 Découverte nouveaux artistes...\n",
      "🆕 Nouveaux artistes: 10\n",
      "💫 Formatage de la playlist...\n",
      "\n",
      "✅ DISCOVER WEEKLY CORRIGÉ!\n",
      "💾 Sauvegardé: fixed_discover_weekly_2c42e655.csv\n",
      "🎵 Tracks générées: 4/15\n",
      "\n",
      "📊 Répartition des sources:\n",
      "   • New Artist: 4 tracks (100.0%)\n",
      "\n",
      "🎧 Aperçu de votre Discover Weekly:\n",
      "   12. Nick Lowe - All Men Are Liars\n",
      "       Source: New Artist\n",
      "   13. Foo Fighters - Still\n",
      "       Source: New Artist\n",
      "   14. Operation Ivy - Knowledge\n",
      "       Source: New Artist\n",
      "   15. Michael Cera & Ellen Page - Anyone Else But You\n",
      "       Source: New Artist\n",
      "\n",
      "🎉 CORRECTIF RÉUSSI!\n",
      "📁 Fichier corrigé disponible dans results/\n",
      "🔄 Remplace le fichier discover_weekly précédent\n"
     ]
    }
   ],
   "source": [
    "# fix_discover_weekly.py - Correctif pour garantir 15 tracks dans Discover Weekly\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def generate_full_discover_weekly():\n",
    "    \"\"\"Génère une Discover Weekly complète avec 15 tracks garanties\"\"\"\n",
    "    \n",
    "    print(\"🔧 CORRECTIF DISCOVER WEEKLY\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Charger données\n",
    "    print(\"📊 Chargement des données...\")\n",
    "    triplets_df = pd.read_csv(\n",
    "        \"train_triplets.txt\", sep='\\t', \n",
    "        names=['user_id', 'song_id', 'play_count'],\n",
    "        nrows=10000\n",
    "    )\n",
    "    \n",
    "    tracks_df = pd.read_csv(\n",
    "        \"p02_unique_tracks.txt\", sep='<SEP>',\n",
    "        names=['track_id', 'song_id', 'artist', 'title'],\n",
    "        engine='python', nrows=5000\n",
    "    )\n",
    "    \n",
    "    users = triplets_df['user_id'].unique()\n",
    "    \n",
    "    # Choisir un utilisateur avec un bon historique\n",
    "    user_song_counts = triplets_df.groupby('user_id').size()\n",
    "    active_users = user_song_counts[user_song_counts >= 10].index  # Au moins 10 chansons\n",
    "    \n",
    "    if len(active_users) > 0:\n",
    "        target_user = random.choice(active_users)\n",
    "    else:\n",
    "        target_user = random.choice(users)\n",
    "    \n",
    "    print(f\"👤 Utilisateur sélectionné: {target_user[:12]}...\")\n",
    "    \n",
    "    # Analyser l'utilisateur\n",
    "    user_songs = triplets_df[triplets_df['user_id'] == target_user]\n",
    "    user_song_ids = set(user_songs['song_id'])\n",
    "    \n",
    "    print(f\"🎵 Historique utilisateur: {len(user_song_ids)} chansons\")\n",
    "    \n",
    "    # 1. Recommendations collaborative (utilisateurs similaires)\n",
    "    print(\"🔍 Recherche utilisateurs similaires...\")\n",
    "    \n",
    "    similar_users = find_similar_users(triplets_df, target_user, user_song_ids, top_k=20)\n",
    "    print(f\"👥 Utilisateurs similaires trouvés: {len(similar_users)}\")\n",
    "    \n",
    "    cf_recommendations = []\n",
    "    for similar_user in similar_users[:10]:  # Top 10 similaires\n",
    "        similar_songs = triplets_df[triplets_df['user_id'] == similar_user]['song_id'].values\n",
    "        new_songs = [s for s in similar_songs if s not in user_song_ids]\n",
    "        cf_recommendations.extend(new_songs[:2])  # 2 par utilisateur similaire\n",
    "    \n",
    "    print(f\"🤝 Recommandations collaborative: {len(set(cf_recommendations))}\")\n",
    "    \n",
    "    # 2. Tracks populaires globales non écoutées\n",
    "    print(\"📈 Recherche tracks populaires...\")\n",
    "    \n",
    "    all_popularity = triplets_df.groupby('song_id')['play_count'].sum().sort_values(ascending=False)\n",
    "    popular_unheard = [song for song in all_popularity.index if song not in user_song_ids]\n",
    "    \n",
    "    print(f\"🔥 Tracks populaires non écoutées: {len(popular_unheard)}\")\n",
    "    \n",
    "    # 3. Découverte par artistes (artistes populaires non écoutés)\n",
    "    print(\"🎤 Découverte nouveaux artistes...\")\n",
    "    \n",
    "    user_artists = set(user_songs.merge(tracks_df, on='song_id')['artist'])\n",
    "    all_tracks_with_artists = triplets_df.merge(tracks_df, on='song_id')\n",
    "    \n",
    "    new_artist_songs = []\n",
    "    artist_popularity = all_tracks_with_artists.groupby('artist')['play_count'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    for artist in artist_popularity.index:\n",
    "        if artist not in user_artists:\n",
    "            artist_tracks = tracks_df[tracks_df['artist'] == artist]['song_id'].values\n",
    "            unheard_from_artist = [s for s in artist_tracks if s not in user_song_ids]\n",
    "            if unheard_from_artist:\n",
    "                # Prendre la plus populaire de cet artiste\n",
    "                best_song = None\n",
    "                best_pop = 0\n",
    "                for song in unheard_from_artist:\n",
    "                    pop = triplets_df[triplets_df['song_id'] == song]['play_count'].sum()\n",
    "                    if pop > best_pop:\n",
    "                        best_pop = pop\n",
    "                        best_song = song\n",
    "                if best_song:\n",
    "                    new_artist_songs.append(best_song)\n",
    "                    if len(new_artist_songs) >= 10:  # Limite\n",
    "                        break\n",
    "    \n",
    "    print(f\"🆕 Nouveaux artistes: {len(new_artist_songs)}\")\n",
    "    \n",
    "    # 4. Combiner toutes les recommandations\n",
    "    all_recommendations = []\n",
    "    \n",
    "    # Ajouter collaborative (40%)\n",
    "    cf_unique = list(set(cf_recommendations))\n",
    "    random.shuffle(cf_unique)\n",
    "    for song in cf_unique[:6]:  # 6 tracks collaborative\n",
    "        all_recommendations.append((song, \"Similar Users\"))\n",
    "    \n",
    "    # Ajouter populaires (35%)\n",
    "    for song in popular_unheard[:5]:  # 5 tracks populaires\n",
    "        if song not in [r[0] for r in all_recommendations]:\n",
    "            all_recommendations.append((song, \"Trending\"))\n",
    "    \n",
    "    # Ajouter nouveaux artistes (25%)\n",
    "    for song in new_artist_songs[:4]:  # 4 nouveaux artistes\n",
    "        if song not in [r[0] for r in all_recommendations]:\n",
    "            all_recommendations.append((song, \"New Artist\"))\n",
    "    \n",
    "    # 5. Compléter jusqu'à 15 si nécessaire\n",
    "    existing_songs = set([r[0] for r in all_recommendations])\n",
    "    \n",
    "    if len(all_recommendations) < 15:\n",
    "        print(f\"🔄 Complément nécessaire: {15 - len(all_recommendations)} tracks\")\n",
    "        \n",
    "        # Ajouter plus de tracks populaires\n",
    "        for song in all_popularity.index:\n",
    "            if song not in existing_songs and song not in user_song_ids:\n",
    "                all_recommendations.append((song, \"Popular Filler\"))\n",
    "                if len(all_recommendations) >= 15:\n",
    "                    break\n",
    "    \n",
    "    # 6. Formatage final\n",
    "    print(\"💫 Formatage de la playlist...\")\n",
    "    \n",
    "    playlist = []\n",
    "    for i, (song_id, reason) in enumerate(all_recommendations[:15], 1):\n",
    "        track_info = tracks_df[tracks_df['song_id'] == song_id]\n",
    "        \n",
    "        if not track_info.empty:\n",
    "            track = track_info.iloc[0]\n",
    "            playlist.append({\n",
    "                'rank': i,\n",
    "                'artist': track['artist'],\n",
    "                'title': track['title'],\n",
    "                'song_id': song_id,\n",
    "                'reason': reason\n",
    "            })\n",
    "    \n",
    "    # 7. Sauvegarder\n",
    "    if playlist:\n",
    "        df = pd.DataFrame(playlist)\n",
    "        filename = f'fixed_discover_weekly_{target_user[:8]}.csv'\n",
    "        filepath = f'results/{filename}'\n",
    "        df.to_csv(filepath, index=False)\n",
    "        \n",
    "        print(f\"\\n✅ DISCOVER WEEKLY CORRIGÉ!\")\n",
    "        print(f\"💾 Sauvegardé: {filename}\")\n",
    "        print(f\"🎵 Tracks générées: {len(playlist)}/15\")\n",
    "        \n",
    "        # Répartition des sources\n",
    "        reason_counts = df['reason'].value_counts()\n",
    "        print(f\"\\n📊 Répartition des sources:\")\n",
    "        for reason, count in reason_counts.items():\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"   • {reason}: {count} tracks ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"\\n🎧 Aperçu de votre Discover Weekly:\")\n",
    "        for _, row in df.head(5).iterrows():\n",
    "            print(f\"   {row['rank']:2d}. {row['artist']} - {row['title']}\")\n",
    "            print(f\"       Source: {row['reason']}\")\n",
    "        \n",
    "        if len(df) > 5:\n",
    "            print(f\"   ... et {len(df)-5} autres découvertes!\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    return None\n",
    "\n",
    "def find_similar_users(triplets_df, target_user, target_songs, top_k=10):\n",
    "    \"\"\"Trouve des utilisateurs similaires plus efficacement\"\"\"\n",
    "    \n",
    "    similarities = []\n",
    "    target_songs_set = set(target_songs)\n",
    "    \n",
    "    # Échantillonner les utilisateurs pour aller plus vite\n",
    "    all_users = triplets_df['user_id'].unique()\n",
    "    sample_users = random.sample(list(all_users), min(200, len(all_users)))\n",
    "    \n",
    "    for user in sample_users:\n",
    "        if user != target_user:\n",
    "            user_songs = set(triplets_df[triplets_df['user_id'] == user]['song_id'])\n",
    "            \n",
    "            # Similarité Jaccard\n",
    "            intersection = len(target_songs_set.intersection(user_songs))\n",
    "            union = len(target_songs_set.union(user_songs))\n",
    "            \n",
    "            if union > 0 and intersection > 0:  # Au moins une chanson en commun\n",
    "                similarity = intersection / union\n",
    "                similarities.append((user, similarity))\n",
    "    \n",
    "    # Trier et retourner top-k\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [user for user, _ in similarities[:top_k]]\n",
    "\n",
    "def main():\n",
    "    \"\"\"Exécute le correctif\"\"\"\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        result = generate_full_discover_weekly()\n",
    "        \n",
    "        if result is not None:\n",
    "            print(f\"\\n🎉 CORRECTIF RÉUSSI!\")\n",
    "            print(f\"📁 Fichier corrigé disponible dans results/\")\n",
    "            print(f\"🔄 Remplace le fichier discover_weekly précédent\")\n",
    "        else:\n",
    "            print(f\"\\n❌ Échec du correctif\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880dbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IA_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
